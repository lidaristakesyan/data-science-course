{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Data Science Course","text":"<p>Welcome to  Picsart Academy Data Science Course \ud83c\udf31</p> <p>Instructor: Lida Aristakesyan</p>"},{"location":"#structure","title":"Structure","text":"<ul> <li>\ud83d\udcda Lecture notes &amp; Slides</li> <li>\ud83d\udcbb Code &amp; notebooks </li> <li>\ud83d\udcdd Homework assignments &amp; solutions</li> </ul>"},{"location":"homeworks/","title":"Course structure","text":""},{"location":"homeworks/#homeworks","title":"Homeworks","text":"<ul> <li>HW1</li> </ul> <p>More homeworks will be added throughout the course period.</p>"},{"location":"lectures/","title":"Course structure","text":"<p>Complete notes for the PA Academy Data Science course.</p>"},{"location":"lectures/#course-outline","title":"Course Outline","text":"<ul> <li>Course Outline</li> </ul>"},{"location":"lectures/#lecture-notes","title":"Lecture Notes","text":"<ul> <li>L01: Data as a Building Block</li> <li>L02: Relational Databases</li> </ul>"},{"location":"lectures/#slides","title":"Slides","text":"<ul> <li>LS01: Data as a Building Block</li> <li>LS02: Relational Databases</li> </ul> <p>More lectures will be added throughout the course period.</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/","title":"Complete SQL Reference Guide","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#from-fundamentals-to-advanced-analytics","title":"From Fundamentals to Advanced Analytics","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#part-1-relational-database-fundamentals","title":"Part 1: Relational Database Fundamentals","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#11-what-is-a-relational-database","title":"1.1 What is a Relational Database?","text":"<p>A relational database is a type of database that organizes data into tables (also called relations) consisting of rows and columns. The \"relational\" part refers to how tables can be linked to each other through shared columns, enabling complex data relationships while minimizing redundancy.</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#core-terminology","title":"Core Terminology","text":"Term Definition Analogy Table (Relation) A collection of related data organized in rows and columns A spreadsheet tab Row (Record/Tuple) A single entry in a table representing one entity One line in a spreadsheet Column (Field/Attribute) A specific piece of data that each row contains A spreadsheet column header Schema The structure/blueprint of a database (tables, columns, relationships) The architectural plan Database A collection of related tables and other objects The entire filing cabinet"},{"location":"lectures/L2-L3-Relational_Database_Systems/#why-relational-databases","title":"Why Relational Databases?","text":"<p>Relational databases solve fundamental data management problems:</p> <ol> <li>Data Integrity: Rules ensure data remains accurate and consistent</li> <li>Reduced Redundancy: Information stored once, referenced many times</li> <li>Flexible Querying: SQL allows complex questions to be answered easily</li> <li>ACID Compliance: Transactions are reliable and predictable</li> <li>Scalability: Can handle growing data volumes efficiently</li> </ol>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#12-keys-the-foundation-of-relationships","title":"1.2 Keys: The Foundation of Relationships","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#primary-key-pk","title":"Primary Key (PK)","text":"<p>A Primary Key is a column (or combination of columns) that uniquely identifies each row in a table.</p> <p>Rules for Primary Keys: - Must be unique \u2014 no two rows can have the same PK value - Cannot be NULL \u2014 every row must have a value - Should be immutable \u2014 ideally never changes once set - Every table should have exactly one</p> <p>Types of Primary Keys:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     PRIMARY KEY TYPES                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502  1. NATURAL KEY                   2. SURROGATE KEY              \u2502\n\u2502     (Real-world identifier)          (Artificial identifier)    \u2502\n\u2502                                                                 \u2502\n\u2502     Examples:                        Examples:                  \u2502\n\u2502     \u2022 Social Security Number         \u2022 Auto-increment ID        \u2502\n\u2502     \u2022 ISBN for books                 \u2022 UUID/GUID                \u2502\n\u2502     \u2022 Email address                  \u2022 Sequence number          \u2502\n\u2502                                                                 \u2502\n\u2502     Pros: Meaningful                 Pros: Simple, stable       \u2502\n\u2502     Cons: Can change, complex        Cons: No business meaning  \u2502\n\u2502                                                                 \u2502\n\u2502  3. COMPOSITE KEY (Multiple columns together)                   \u2502\n\u2502     Example: (student_id, course_id) for enrollments            \u2502\n\u2502                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>SQL Examples:</p> <pre><code>-- Single column primary key (most common)\nCREATE TABLE customers (\n    customer_id INT PRIMARY KEY,\n    name VARCHAR(100),\n    email VARCHAR(100)\n);\n\n-- Auto-increment primary key\nCREATE TABLE customers (\n    customer_id SERIAL PRIMARY KEY,  -- PostgreSQL\n    -- customer_id INT AUTO_INCREMENT PRIMARY KEY,  -- MySQL\n    name VARCHAR(100),\n    email VARCHAR(100)\n);\n\n-- Composite primary key\nCREATE TABLE order_items (\n    order_id INT,\n    product_id INT,\n    quantity INT,\n    PRIMARY KEY (order_id, product_id)\n);\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#foreign-key-fk","title":"Foreign Key (FK)","text":"<p>A Foreign Key is a column that references a Primary Key in another table, creating a relationship between the two tables.</p> <p>What Foreign Keys Do: - Create relationships between tables - Enforce referential integrity (can't reference non-existent records) - Enable JOIN operations - Prevent orphan records</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      customers      \u2502              \u2502       orders        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524              \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer_id (PK) \u25cf\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u25cb customer_id (FK) \u2502\n\u2502 name                \u2502              \u2502 order_id (PK)       \u2502\n\u2502 email               \u2502              \u2502 order_date          \u2502\n\u2502 city                \u2502              \u2502 total_amount        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u25cf = Primary Key (unique identifier)\n\u25cb = Foreign Key (reference to another table)\n</code></pre> <p>SQL Example:</p> <pre><code>CREATE TABLE orders (\n    order_id INT PRIMARY KEY,\n    customer_id INT,\n    order_date DATE,\n    total_amount DECIMAL(10,2),\n    FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n);\n</code></pre> <p>Referential Integrity Actions:</p> <pre><code>CREATE TABLE orders (\n    order_id INT PRIMARY KEY,\n    customer_id INT,\n    FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n        ON DELETE CASCADE      -- Delete orders when customer deleted\n        ON UPDATE CASCADE      -- Update FK when customer PK changes\n);\n\n-- Other options:\n-- ON DELETE SET NULL     -- Set FK to NULL when parent deleted\n-- ON DELETE RESTRICT     -- Prevent deletion if children exist\n-- ON DELETE NO ACTION    -- Same as RESTRICT (default)\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#13-types-of-relationships","title":"1.3 Types of Relationships","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#one-to-many-1n-most-common","title":"One-to-Many (1:N) \u2014 Most Common","text":"<p>One record in Table A can relate to many records in Table B, but each record in Table B relates to only one record in Table A.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      customers      \u2502         \u2502       orders        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524         \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer_id (PK)    \u2502\u25c4\u2500\u2500\u2500\u2510    \u2502 order_id (PK)       \u2502\n\u2502 name                \u2502    \u2502    \u2502 customer_id (FK) \u2500\u2500\u2500\u2518\n\u2502 email               \u2502    \u2502    \u2502 order_date          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502 total_amount        \u2502\n                           \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n    One customer \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Many orders\n</code></pre> <p>Real-world examples: - One customer \u2192 Many orders - One department \u2192 Many employees - One author \u2192 Many blog posts - One category \u2192 Many products</p> <p>Implementation: Place the FK in the \"many\" side table.</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#one-to-one-11-rare","title":"One-to-One (1:1) \u2014 Rare","text":"<p>Each record in Table A relates to exactly one record in Table B, and vice versa.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       users         \u2502         \u2502    user_profiles    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524         \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 user_id (PK)        \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 user_id (PK, FK)    \u2502\n\u2502 email               \u2502         \u2502 bio                 \u2502\n\u2502 password_hash       \u2502         \u2502 avatar_url          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502 preferences_json    \u2502\n                                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>When to use: - Optional data that doesn't apply to all records - Security separation (sensitive data in separate table) - Very large columns that are rarely accessed - Exceeding column limits in a table</p> <p>Implementation: FK in either table (usually the optional one), often also the PK.</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#many-to-many-mn","title":"Many-to-Many (M:N)","text":"<p>Many records in Table A can relate to many records in Table B.</p> <p>Problem: Cannot be directly represented with just two tables.</p> <p>Solution: Create a junction table (also called bridge/associative table).</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      students       \u2502                           \u2502       courses       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524                           \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 student_id (PK)     \u2502\u25c4\u2500\u2500\u2500\u2510                 \u250c\u2500\u2500\u2500\u25ba\u2502 course_id (PK)      \u2502\n\u2502 name                \u2502    \u2502                 \u2502    \u2502 course_name         \u2502\n\u2502 email               \u2502    \u2502                 \u2502    \u2502 credits             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502                 \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502                 \u2502\n                           \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                           \u2502  \u2502     enrollments       \u2502\n                           \u2502  \u2502   (junction table)    \u2502\n                           \u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                           \u2514\u2500\u2500\u2502 student_id (FK, PK)   \u2502\n                              \u2502 course_id (FK, PK)  \u2500\u2500\u2518\n                              \u2502 enrollment_date       \u2502\n                              \u2502 grade                 \u2502\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>CREATE TABLE enrollments (\n    student_id INT,\n    course_id INT,\n    enrollment_date DATE,\n    grade CHAR(2),\n    PRIMARY KEY (student_id, course_id),  -- Composite PK\n    FOREIGN KEY (student_id) REFERENCES students(student_id),\n    FOREIGN KEY (course_id) REFERENCES courses(course_id)\n);\n</code></pre> <p>Real-world examples: - Students \u2194 Courses (via enrollments) - Products \u2194 Orders (via order_items) - Users \u2194 Roles (via user_roles) - Authors \u2194 Books (via book_authors)</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#14-sql-data-types","title":"1.4 SQL Data Types","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#numeric-types","title":"Numeric Types","text":"Type Description Range/Precision Use Case <code>TINYINT</code> Very small integer -128 to 127 Status codes, flags <code>SMALLINT</code> Small integer -32,768 to 32,767 Counts, years <code>INT</code>/<code>INTEGER</code> Standard integer ~\u00b12.1 billion IDs, counts <code>BIGINT</code> Large integer ~\u00b19.2 quintillion Large IDs, timestamps <code>DECIMAL(p,s)</code> Fixed precision p digits, s after decimal Money, exact values <code>NUMERIC(p,s)</code> Same as DECIMAL p digits, s after decimal Money, exact values <code>FLOAT</code> Single precision ~7 significant digits Scientific data <code>DOUBLE</code>/<code>REAL</code> Double precision ~15 significant digits Scientific data <pre><code>-- DECIMAL is crucial for money (no floating point errors)\nCREATE TABLE products (\n    price DECIMAL(10, 2),     -- 10 digits total, 2 after decimal\n    tax_rate DECIMAL(5, 4)    -- e.g., 0.0825 for 8.25%\n);\n\n-- NEVER use FLOAT for money!\n-- 0.1 + 0.2 = 0.30000000000000004 in floating point\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#string-types","title":"String Types","text":"Type Description Max Length Use Case <code>CHAR(n)</code> Fixed-length string n characters (padded) Country codes, status <code>VARCHAR(n)</code> Variable-length string Up to n characters Names, emails <code>TEXT</code> Long text ~65KB to unlimited Descriptions, articles <code>MEDIUMTEXT</code> Medium long text ~16MB Blog posts <code>LONGTEXT</code> Very long text ~4GB Documents <pre><code>-- CHAR vs VARCHAR\nCREATE TABLE countries (\n    country_code CHAR(2),       -- Always 2 chars: 'US', 'CA'\n    country_name VARCHAR(100)   -- Variable: 'USA', 'United Kingdom'\n);\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#date-and-time-types","title":"Date and Time Types","text":"Type Format Example Use Case <code>DATE</code> YYYY-MM-DD 2025-11-29 Birthdates, due dates <code>TIME</code> HH:MM:SS 14:30:00 Schedules, durations <code>DATETIME</code> YYYY-MM-DD HH:MM:SS 2025-11-29 14:30:00 Events, logs <code>TIMESTAMP</code> Unix timestamp or datetime 2025-11-29 14:30:00 UTC Auto-tracking, sync <code>YEAR</code> YYYY 2025 Years only <pre><code>CREATE TABLE events (\n    event_date DATE,\n    start_time TIME,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP\n);\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#other-types","title":"Other Types","text":"Type Description Use Case <code>BOOLEAN</code> TRUE/FALSE Flags, toggles <code>ENUM</code> Predefined values Status, categories <code>JSON</code> JSON data Flexible schemas <code>BLOB</code> Binary data Images, files <code>UUID</code> Universally unique ID Distributed systems <pre><code>CREATE TABLE users (\n    is_active BOOLEAN DEFAULT TRUE,\n    status ENUM('pending', 'active', 'suspended'),\n    preferences JSON,\n    avatar BLOB\n);\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#15-acid-properties","title":"1.5 ACID Properties","text":"<p>ACID properties ensure database transactions are processed reliably.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            ACID PROPERTIES                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557    A transaction is an \"all or nothing\" operation.       \u2502\n\u2502  \u2551  ATOMICITY    \u2551    Either ALL operations succeed, or NONE do.            \u2502\n\u2502  \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d    Example: Bank transfer - debit AND credit both        \u2502\n\u2502                       happen, or neither happens.                           \u2502\n\u2502                                                                             \u2502\n\u2502  \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557    Database moves from one valid state to another.       \u2502\n\u2502  \u2551  CONSISTENCY  \u2551    All rules, constraints, and triggers are enforced.    \u2502\n\u2502  \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d    Example: Account balance can never go negative        \u2502\n\u2502                       if that's a defined constraint.                       \u2502\n\u2502                                                                             \u2502\n\u2502  \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557    Concurrent transactions don't interfere.              \u2502\n\u2502  \u2551  ISOLATION    \u2551    Each transaction sees a consistent snapshot.          \u2502\n\u2502  \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d    Example: Two people buying last item - only one       \u2502\n\u2502                       succeeds, the other sees \"out of stock.\"              \u2502\n\u2502                                                                             \u2502\n\u2502  \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557    Committed transactions are permanent.                 \u2502\n\u2502  \u2551  DURABILITY   \u2551    Data survives system crashes, power failures.         \u2502\n\u2502  \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d    Example: Confirmed order stays confirmed even         \u2502\n\u2502                       if server crashes immediately after.                  \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Transaction Example:</p> <pre><code>-- Bank transfer: Move $100 from Account A to Account B\nBEGIN TRANSACTION;\n\nUPDATE accounts SET balance = balance - 100 WHERE account_id = 'A';\nUPDATE accounts SET balance = balance + 100 WHERE account_id = 'B';\n\n-- If both succeed:\nCOMMIT;\n\n-- If anything fails:\nROLLBACK;  -- Undoes everything, account balances unchanged\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#part-2-database-normalization","title":"Part 2: Database Normalization","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#21-why-normalize","title":"2.1 Why Normalize?","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#the-problem-non-normalized-data","title":"The Problem: Non-Normalized Data","text":"<p>Consider storing all order information in a single table:</p> <p>orders_denormalized | order_id | customer_name | customer_email | city | product | price | qty | |----------|---------------|----------------|------|---------|-------|-----| | 101 | Alice | alice@email.com | NYC | Laptop | 999.00 | 1 | | 102 | Alice | alice@email.com | NYC | Mouse | 29.00 | 2 | | 103 | Alice | alice@email.com | NYC | Keyboard | 79.00 | 1 | | 104 | Bob | bob@email.com | LA | Laptop | 999.00 | 1 |</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#problems-identified","title":"Problems Identified","text":"<p>1. Data Redundancy - Alice's name, email, and city are stored 3 times - \"Laptop\" price is stored twice - Wastes storage space - More data to maintain</p> <p>2. Update Anomaly If Alice changes her email, you must update EVERY row:</p> <pre><code>-- Must update 3 rows!\nUPDATE orders_denormalized\nSET customer_email = 'alice.new@email.com'\nWHERE customer_name = 'Alice';\n\n-- RISK: If you miss one row, data becomes inconsistent\n</code></pre> <p>3. Insert Anomaly Can't add a new customer until they place an order:</p> <pre><code>-- FAILS! What values for order_id, product, price, qty?\nINSERT INTO orders_denormalized (customer_name, customer_email, city)\nVALUES ('Charlie', 'charlie@email.com', 'Chicago');\n</code></pre> <p>4. Delete Anomaly Deleting Bob's only order loses Bob's information entirely:</p> <pre><code>-- Bob is gone from the database!\nDELETE FROM orders_denormalized WHERE customer_name = 'Bob';\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#the-solution-normalization","title":"The Solution: Normalization","text":"<p>Normalization is the process of organizing data into multiple related tables, each storing one type of entity, to eliminate redundancy and prevent anomalies.</p> <pre><code>                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502    customers    \u2502\n                    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                    \u2502 customer_id (PK)\u2502\n                    \u2502 name            \u2502\n                    \u2502 email           \u2502\n                    \u2502 city            \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n                             \u2502 1:N\n                             \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502     orders      \u2502\n                    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                    \u2502 order_id (PK)   \u2502\n                    \u2502 customer_id (FK)\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502 order_date      \u2502          \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n                             \u2502                   \u2502\n                             \u2502 1:N               \u2502\n                             \u2502                   \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n                    \u2502   order_items   \u2502          \u2502\n                    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524          \u2502\n                    \u2502 order_id (FK,PK)\u2502          \u2502\n                    \u2502 product_id(FK,PK)\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2510\n                    \u2502 quantity        \u2502          \u2502   \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502   \u2502\n                                                 \u2502   \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502   \u2502\n                    \u2502    products     \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n                    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524              \u2502\n                    \u2502 product_id (PK) \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502 name            \u2502\n                    \u2502 price           \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#22-normal-forms","title":"2.2 Normal Forms","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#first-normal-form-1nf","title":"First Normal Form (1NF)","text":"<p>Requirements: 1. Each column contains only atomic (indivisible) values 2. No repeating groups or arrays within a cell 3. Each row is unique (has a primary key) 4. Each column has a unique name</p> <p>Violation Example:</p> order_id customer products 101 Alice Laptop, Mouse, Keyboard <p>Problem: Multiple values in the \"products\" cell. Cannot easily query individual products.</p> <p>1NF Solution:</p> order_id customer product 101 Alice Laptop 101 Alice Mouse 101 Alice Keyboard <pre><code>-- Non-1NF (bad - array in column)\nCREATE TABLE orders_bad (\n    order_id INT,\n    customer VARCHAR(100),\n    products TEXT  -- \"Laptop, Mouse, Keyboard\"\n);\n\n-- 1NF compliant\nCREATE TABLE order_items (\n    order_id INT,\n    customer VARCHAR(100),\n    product VARCHAR(100),\n    PRIMARY KEY (order_id, product)\n);\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#second-normal-form-2nf","title":"Second Normal Form (2NF)","text":"<p>Requirements: 1. Must be in 1NF 2. No partial dependencies \u2014 every non-key column depends on the ENTIRE primary key, not just part of it</p> <p>Only applies to tables with composite primary keys.</p> <p>Violation Example:</p> <p>Composite PK: (order_id, product_id)</p> order_id product_id customer_name product_name quantity 101 1 Alice Laptop 1 <p>Problems: - <code>customer_name</code> depends only on <code>order_id</code> (partial dependency) - <code>product_name</code> depends only on <code>product_id</code> (partial dependency)</p> <p>2NF Solution: Split into separate tables:</p> <pre><code>-- orders table (customer depends on full order)\nCREATE TABLE orders (\n    order_id INT PRIMARY KEY,\n    customer_id INT\n);\n\n-- products table (product_name depends on full product)\nCREATE TABLE products (\n    product_id INT PRIMARY KEY,\n    product_name VARCHAR(100)\n);\n\n-- order_items (quantity depends on both order AND product)\nCREATE TABLE order_items (\n    order_id INT,\n    product_id INT,\n    quantity INT,\n    PRIMARY KEY (order_id, product_id)\n);\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#third-normal-form-3nf","title":"Third Normal Form (3NF)","text":"<p>Requirements: 1. Must be in 2NF 2. No transitive dependencies \u2014 non-key columns cannot depend on other non-key columns</p> <p>Violation Example:</p> customer_id name city city_zip 1 Alice NYC 10001 2 Bob NYC 10001 <p>Problem: <code>city_zip</code> depends on <code>city</code>, not directly on <code>customer_id</code>. This is a transitive dependency: <pre><code>customer_id \u2192 city \u2192 city_zip\n</code></pre></p> <p>3NF Solution:</p> <pre><code>-- customers table\nCREATE TABLE customers (\n    customer_id INT PRIMARY KEY,\n    name VARCHAR(100),\n    city_id INT\n);\n\n-- cities table\nCREATE TABLE cities (\n    city_id INT PRIMARY KEY,\n    city_name VARCHAR(100),\n    zip_code VARCHAR(10)\n);\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#summary-of-normal-forms","title":"Summary of Normal Forms","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         NORMAL FORMS PROGRESSION                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                            \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502   \u2502   1NF   \u2502  \u25ba Atomic values only                                        \u2502\n\u2502   \u2502         \u2502  \u25ba No repeating groups                                       \u2502\n\u2502   \u2502         \u2502  \u25ba Has primary key                                           \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502        \u2502                                                                   \u2502\n\u2502        \u25bc                                                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502   \u2502   2NF   \u2502  \u25ba Must be in 1NF                                            \u2502\n\u2502   \u2502         \u2502  \u25ba No partial dependencies                                   \u2502\n\u2502   \u2502         \u2502  \u25ba (All columns depend on ENTIRE PK)                         \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502        \u2502                                                                   \u2502\n\u2502        \u25bc                                                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502   \u2502   3NF   \u2502  \u25ba Must be in 2NF                                            \u2502\n\u2502   \u2502         \u2502  \u25ba No transitive dependencies                                \u2502\n\u2502   \u2502         \u2502  \u25ba (Non-key columns don't depend on each other)              \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502        \u2502                                                                   \u2502\n\u2502        \u25bc                                                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502   \u2502  BCNF   \u2502  \u25ba Must be in 3NF                                            \u2502\n\u2502   \u2502         \u2502  \u25ba Every determinant is a candidate key                      \u2502\n\u2502   \u2502         \u2502  \u25ba (Stricter version of 3NF)                                 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502                                                                            \u2502\n\u2502   Most production databases aim for 3NF \u2014 good balance of                  \u2502\n\u2502   data integrity and query performance.                                    \u2502\n\u2502                                                                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#higher-normal-forms-brief-overview","title":"Higher Normal Forms (Brief Overview)","text":"<p>Boyce-Codd Normal Form (BCNF): - Stricter than 3NF - Every determinant must be a candidate key - Handles rare edge cases in 3NF</p> <p>Fourth Normal Form (4NF): - No multi-valued dependencies - Example: Employee skills and languages stored separately</p> <p>Fifth Normal Form (5NF): - No join dependencies - Extremely rare in practice</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#23-when-to-denormalize","title":"2.3 When to Denormalize","text":"<p>While normalization is generally good, denormalization (intentionally violating normal forms) is sometimes used for performance.</p> <p>Scenarios for Denormalization:</p> Scenario Why Denormalize? Read-heavy workloads JOINs are expensive; pre-joined data speeds up reads Data warehouses Analytics queries benefit from star/snowflake schemas Reporting tables Pre-aggregate data for dashboards Caching layers Store computed values for performance High-traffic applications Reduce query complexity at read time <p>Example: Storing order total instead of calculating</p> <pre><code>-- Normalized (calculate total each time)\nSELECT SUM(oi.quantity * p.price) as total\nFROM order_items oi\nJOIN products p ON oi.product_id = p.product_id\nWHERE oi.order_id = 101;\n\n-- Denormalized (stored total)\nSELECT total_amount FROM orders WHERE order_id = 101;\n</code></pre> <p>Trade-off: Faster reads, but must update <code>total_amount</code> whenever items change.</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#part-3-sql-queries-from-basic-to-advanced","title":"Part 3: SQL Queries - From Basic to Advanced","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#31-select-reading-data","title":"3.1 SELECT - Reading Data","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#basic-select","title":"Basic SELECT","text":"<pre><code>-- Select all columns from a table\nSELECT * FROM customers;\n\n-- Select specific columns\nSELECT customer_id, name, email FROM customers;\n\n-- Select with column aliases\nSELECT \n    customer_id AS id,\n    name AS customer_name,\n    email AS contact_email\nFROM customers;\n\n-- Select with expressions\nSELECT \n    product_name,\n    price,\n    price * 0.9 AS discounted_price,\n    price * 1.08 AS price_with_tax\nFROM products;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#distinct-removing-duplicates","title":"DISTINCT - Removing Duplicates","text":"<pre><code>-- Get unique cities\nSELECT DISTINCT city FROM customers;\n\n-- Get unique combinations\nSELECT DISTINCT city, state FROM customers;\n\n-- Count unique values\nSELECT COUNT(DISTINCT city) AS unique_cities FROM customers;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#32-where-filtering-data","title":"3.2 WHERE - Filtering Data","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#comparison-operators","title":"Comparison Operators","text":"<pre><code>-- Equals\nSELECT * FROM products WHERE price = 99.99;\n\n-- Not equals\nSELECT * FROM products WHERE category &lt;&gt; 'Electronics';\nSELECT * FROM products WHERE category != 'Electronics';\n\n-- Greater than / Less than\nSELECT * FROM orders WHERE total_amount &gt; 100;\nSELECT * FROM orders WHERE total_amount &gt;= 100;\nSELECT * FROM orders WHERE order_date &lt; '2025-01-01';\nSELECT * FROM orders WHERE order_date &lt;= '2025-01-01';\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#logical-operators","title":"Logical Operators","text":"<pre><code>-- AND (all conditions must be true)\nSELECT * FROM orders \nWHERE total_amount &gt; 100 \n  AND order_date &gt;= '2025-01-01';\n\n-- OR (at least one condition must be true)\nSELECT * FROM customers \nWHERE city = 'NYC' \n   OR city = 'LA';\n\n-- NOT (negates condition)\nSELECT * FROM products \nWHERE NOT category = 'Electronics';\n\n-- Combined with parentheses\nSELECT * FROM orders \nWHERE (status = 'pending' OR status = 'processing')\n  AND total_amount &gt; 50;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#special-operators","title":"Special Operators","text":"<pre><code>-- IN (match any value in list)\nSELECT * FROM customers \nWHERE city IN ('NYC', 'LA', 'Chicago', 'Miami');\n\n-- NOT IN\nSELECT * FROM customers \nWHERE city NOT IN ('NYC', 'LA');\n\n-- BETWEEN (inclusive range)\nSELECT * FROM orders \nWHERE order_date BETWEEN '2025-01-01' AND '2025-12-31';\n\nSELECT * FROM products \nWHERE price BETWEEN 10 AND 100;\n\n-- LIKE (pattern matching)\nSELECT * FROM customers WHERE email LIKE '%@gmail.com';   -- Ends with\nSELECT * FROM customers WHERE name LIKE 'John%';          -- Starts with\nSELECT * FROM customers WHERE name LIKE '%son%';          -- Contains\nSELECT * FROM products WHERE sku LIKE 'PRD-___';          -- Exactly 3 chars after PRD-\n\n-- IS NULL / IS NOT NULL\nSELECT * FROM customers WHERE phone IS NULL;\nSELECT * FROM orders WHERE shipped_date IS NOT NULL;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#33-order-by-limit","title":"3.3 ORDER BY &amp; LIMIT","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#order-by-sorting-results","title":"ORDER BY - Sorting Results","text":"<pre><code>-- Sort ascending (default)\nSELECT * FROM products ORDER BY price;\nSELECT * FROM products ORDER BY price ASC;\n\n-- Sort descending\nSELECT * FROM products ORDER BY price DESC;\n\n-- Multiple columns (sort by first, then by second for ties)\nSELECT * FROM orders \nORDER BY customer_id ASC, order_date DESC;\n\n-- Sort by expression\nSELECT product_name, price, price * quantity AS total\nFROM order_items\nORDER BY price * quantity DESC;\n\n-- Sort by column position (not recommended for readability)\nSELECT customer_id, name, city FROM customers\nORDER BY 3;  -- Sorts by city\n\n-- Sort with NULLs first/last\nSELECT * FROM employees ORDER BY manager_id NULLS FIRST;\nSELECT * FROM employees ORDER BY manager_id NULLS LAST;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#limit-restricting-results","title":"LIMIT - Restricting Results","text":"<pre><code>-- Get first 10 rows\nSELECT * FROM customers LIMIT 10;\n\n-- Top 5 highest spending customers\nSELECT customer_id, SUM(total_amount) AS total_spent\nFROM orders\nGROUP BY customer_id\nORDER BY total_spent DESC\nLIMIT 5;\n\n-- Pagination (OFFSET)\n-- Page 1: rows 1-10\nSELECT * FROM products ORDER BY product_id LIMIT 10 OFFSET 0;\n\n-- Page 2: rows 11-20\nSELECT * FROM products ORDER BY product_id LIMIT 10 OFFSET 10;\n\n-- Page 3: rows 21-30\nSELECT * FROM products ORDER BY product_id LIMIT 10 OFFSET 20;\n\n-- Alternative syntax (MySQL)\nSELECT * FROM products ORDER BY product_id LIMIT 10, 10;  -- LIMIT offset, count\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#34-aggregate-functions","title":"3.4 Aggregate Functions","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#basic-aggregates","title":"Basic Aggregates","text":"<pre><code>-- COUNT - number of rows\nSELECT COUNT(*) AS total_rows FROM orders;\nSELECT COUNT(phone) AS customers_with_phone FROM customers;  -- Excludes NULLs\nSELECT COUNT(DISTINCT customer_id) AS unique_customers FROM orders;\n\n-- SUM - total of numeric values\nSELECT SUM(total_amount) AS total_revenue FROM orders;\n\n-- AVG - average value\nSELECT AVG(total_amount) AS avg_order_value FROM orders;\n\n-- MIN / MAX\nSELECT MIN(price) AS cheapest, MAX(price) AS most_expensive FROM products;\nSELECT MIN(order_date) AS first_order, MAX(order_date) AS last_order FROM orders;\n\n-- Multiple aggregates together\nSELECT \n    COUNT(*) AS num_orders,\n    SUM(total_amount) AS total_revenue,\n    AVG(total_amount) AS avg_order,\n    MIN(total_amount) AS smallest_order,\n    MAX(total_amount) AS largest_order\nFROM orders;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#35-group-by-grouping-data","title":"3.5 GROUP BY - Grouping Data","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#basic-grouping","title":"Basic Grouping","text":"<pre><code>-- Orders per customer\nSELECT \n    customer_id,\n    COUNT(*) AS num_orders,\n    SUM(total_amount) AS total_spent,\n    AVG(total_amount) AS avg_order_value\nFROM orders\nGROUP BY customer_id;\n\n-- Products per category\nSELECT \n    category,\n    COUNT(*) AS product_count,\n    AVG(price) AS avg_price,\n    MIN(price) AS min_price,\n    MAX(price) AS max_price\nFROM products\nGROUP BY category;\n\n-- Multiple grouping columns\nSELECT \n    strftime('%Y', order_date) AS year,\n    strftime('%m', order_date) AS month,\n    COUNT(*) AS num_orders,\n    SUM(total_amount) AS monthly_revenue\nFROM orders\nGROUP BY strftime('%Y', order_date), strftime('%m', order_date)\nORDER BY year, month;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#36-having-filtering-groups","title":"3.6 HAVING - Filtering Groups","text":"<p>WHERE filters rows BEFORE grouping. HAVING filters groups AFTER aggregation.</p> <pre><code>-- Customers with more than 5 orders\nSELECT \n    customer_id,\n    COUNT(*) AS num_orders\nFROM orders\nGROUP BY customer_id\nHAVING COUNT(*) &gt; 5;\n\n-- Categories with average price over $50\nSELECT \n    category,\n    AVG(price) AS avg_price\nFROM products\nGROUP BY category\nHAVING AVG(price) &gt; 50;\n\n-- Combined WHERE and HAVING\nSELECT \n    customer_id,\n    COUNT(*) AS num_orders,\n    SUM(total_amount) AS total_spent\nFROM orders\nWHERE order_date &gt;= '2025-01-01'    -- Filter rows first\nGROUP BY customer_id\nHAVING SUM(total_amount) &gt; 1000;    -- Then filter groups\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#where-vs-having-comparison","title":"WHERE vs HAVING Comparison","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      WHERE vs HAVING                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                     \u2502\n\u2502   WHERE                          HAVING                             \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500      \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500          \u2502\n\u2502   \u2022 Filters individual ROWS      \u2022 Filters GROUPS                   \u2502\n\u2502   \u2022 Applied BEFORE grouping      \u2022 Applied AFTER grouping           \u2502\n\u2502   \u2022 Cannot use aggregates        \u2022 Can use aggregate functions      \u2502\n\u2502   \u2022 Faster (reduces data early)  \u2022 Works on aggregated results      \u2502\n\u2502                                                                     \u2502\n\u2502   Example:                       Example:                           \u2502\n\u2502   WHERE order_date &gt; '2025'      HAVING COUNT(*) &gt; 5                \u2502\n\u2502   WHERE price &lt; 100              HAVING SUM(amount) &gt; 1000          \u2502\n\u2502                                                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#part-4-joins-combining-tables","title":"Part 4: JOINs - Combining Tables","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#41-understanding-joins","title":"4.1 Understanding JOINs","text":"<p>JOINs combine rows from two or more tables based on a related column. This is essential for working with normalized databases.</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#sample-tables-for-examples","title":"Sample Tables for Examples","text":"<p>customers | customer_id | name | city | |-------------|------|------| | 1 | Alice | NYC | | 2 | Bob | LA | | 3 | Carol | Chicago | | 4 | David | Miami |</p> <p>orders | order_id | customer_id | amount | |----------|-------------|--------| | 101 | 1 | 150.00 | | 102 | 1 | 200.00 | | 103 | 2 | 75.00 | | 104 | 5 | 300.00 |</p> <p>Note: Customer 3, 4 have no orders. Order 104 has customer_id=5 (doesn't exist).</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#42-inner-join","title":"4.2 INNER JOIN","text":"<p>Returns only rows where there's a match in BOTH tables.</p> <p>Mathematical Definition: INNER JOIN \u2248 Set Intersection (for matching criteria)</p> <pre><code>    customers                orders               INNER JOIN Result\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  1 Alice  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  1  150   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Alice  1   150  \u2502\n  \u2502  2 Bob    \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  1  200   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Alice  1   200  \u2502\n  \u2502  3 Carol  \u2502    \u2573     \u2502  2   75   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Bob    2    75  \u2502\n  \u2502  4 David  \u2502    \u2573     \u2502  5  300   \u2502    \u2573     \u2502                 \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2573 = No match, excluded from result\n</code></pre> <pre><code>-- Basic INNER JOIN\nSELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.amount\nFROM customers c\nINNER JOIN orders o ON c.customer_id = o.customer_id;\n</code></pre> <p>Result: | customer_id | name | order_id | amount | |-------------|------|----------|--------| | 1 | Alice | 101 | 150.00 | | 1 | Alice | 102 | 200.00 | | 2 | Bob | 103 | 75.00 |</p> <p>Carol and David are excluded (no orders). Order 104 is excluded (customer doesn't exist).</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#43-left-join-left-outer-join","title":"4.3 LEFT JOIN (LEFT OUTER JOIN)","text":"<p>Returns ALL rows from the left table, plus matching rows from the right table. Non-matching right columns are NULL.</p> <pre><code>    customers                orders               LEFT JOIN Result\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  1 Alice  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  1  150   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Alice  1   150   \u2502\n  \u2502  2 Bob    \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  1  200   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Alice  1   200   \u2502\n  \u2502  3 Carol  \u2502\u2500\u2500NULL\u2500\u2500\u2500\u2500\u2502  2   75   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Bob    2    75   \u2502\n  \u2502  4 David  \u2502\u2500\u2500NULL\u2500\u2500\u2500\u2500\u2502  5  300   \u2502    \u2573     \u2502 Carol  3   NULL  \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502 David  4   NULL  \u2502\n                                                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>-- LEFT JOIN\nSELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.amount\nFROM customers c\nLEFT JOIN orders o ON c.customer_id = o.customer_id;\n</code></pre> <p>Result: | customer_id | name | order_id | amount | |-------------|------|----------|--------| | 1 | Alice | 101 | 150.00 | | 1 | Alice | 102 | 200.00 | | 2 | Bob | 103 | 75.00 | | 3 | Carol | NULL | NULL | | 4 | David | NULL | NULL |</p> <p>Use Cases: - Find all customers and their orders (including those with no orders) - Count orders per customer (including zero) - Find records that DON'T have matching records</p> <pre><code>-- Find customers who have never ordered\nSELECT c.customer_id, c.name\nFROM customers c\nLEFT JOIN orders o ON c.customer_id = o.customer_id\nWHERE o.order_id IS NULL;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#44-right-join-right-outer-join","title":"4.4 RIGHT JOIN (RIGHT OUTER JOIN)","text":"<p>Returns ALL rows from the right table, plus matching rows from the left table. Non-matching left columns are NULL.</p> <pre><code>    customers                orders               RIGHT JOIN Result\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  1 Alice  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  1  150   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Alice  1   150   \u2502\n  \u2502  2 Bob    \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  1  200   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Alice  1   200   \u2502\n  \u2502  3 Carol  \u2502    \u2573     \u2502  2   75   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Bob    2    75   \u2502\n  \u2502  4 David  \u2502    \u2573     \u2502  5  300   \u2502\u2500\u2500NULL\u2500\u2500\u2500\u2500\u2502 NULL   5   300   \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>-- RIGHT JOIN (less commonly used - can usually be rewritten as LEFT JOIN)\nSELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.amount\nFROM customers c\nRIGHT JOIN orders o ON c.customer_id = o.customer_id;\n</code></pre> <p>Result: | customer_id | name | order_id | amount | |-------------|------|----------|--------| | 1 | Alice | 101 | 150.00 | | 1 | Alice | 102 | 200.00 | | 2 | Bob | 103 | 75.00 | | NULL | NULL | 104 | 300.00 |</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#45-full-outer-join","title":"4.5 FULL OUTER JOIN","text":"<p>Returns ALL rows from BOTH tables. NULL where there's no match.</p> <pre><code>    customers                orders               FULL OUTER Result\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502  1 Alice  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  1  150   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Alice  1   150   \u2502\n  \u2502  2 Bob    \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  1  200   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Alice  1   200   \u2502\n  \u2502  3 Carol  \u2502\u2500\u2500NULL\u2500\u2500\u2500\u2500\u2502  2   75   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Bob    2    75   \u2502\n  \u2502  4 David  \u2502\u2500\u2500NULL\u2500\u2500\u2500\u2500\u2502  5  300   \u2502\u2500\u2500NULL\u2500\u2500\u2500\u2500\u2502 Carol  3   NULL  \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502 David  4   NULL  \u2502\n                                                \u2502 NULL   5   300   \u2502\n                                                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>-- FULL OUTER JOIN\nSELECT \n    c.customer_id,\n    c.name,\n    o.order_id,\n    o.amount\nFROM customers c\nFULL OUTER JOIN orders o ON c.customer_id = o.customer_id;\n</code></pre> <p>Result: | customer_id | name | order_id | amount | |-------------|------|----------|--------| | 1 | Alice | 101 | 150.00 | | 1 | Alice | 102 | 200.00 | | 2 | Bob | 103 | 75.00 | | 3 | Carol | NULL | NULL | | 4 | David | NULL | NULL | | NULL | NULL | 104 | 300.00 |</p> <p>Note: MySQL doesn't support FULL OUTER JOIN directly. Use UNION:</p> <pre><code>-- MySQL workaround for FULL OUTER JOIN\nSELECT c.*, o.order_id, o.amount\nFROM customers c\nLEFT JOIN orders o ON c.customer_id = o.customer_id\n\nUNION\n\nSELECT c.*, o.order_id, o.amount\nFROM customers c\nRIGHT JOIN orders o ON c.customer_id = o.customer_id\nWHERE c.customer_id IS NULL;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#46-cross-join-cartesian-product","title":"4.6 CROSS JOIN (Cartesian Product)","text":"<p>Returns every combination of rows from both tables. No join condition.</p> <p>Mathematical Definition: A \u00d7 B = {(a,b) | a \u2208 A and b \u2208 B}</p> <pre><code>-- CROSS JOIN (explicit syntax)\nSELECT c.name, p.product_name\nFROM customers c\nCROSS JOIN products p;\n\n-- CROSS JOIN (implicit syntax)\nSELECT c.name, p.product_name\nFROM customers c, products p;\n</code></pre> <p>If customers has 4 rows and products has 10 rows, result has 4 \u00d7 10 = 40 rows.</p> <p>Use Cases: - Generate all possible combinations - Create date scaffolds for reporting - Expand data for analysis</p> <pre><code>-- Generate all date-product combinations for inventory tracking\nSELECT d.date, p.product_id\nFROM dates d\nCROSS JOIN products p;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#47-self-join","title":"4.7 SELF JOIN","text":"<p>Joining a table to itself. Useful for hierarchical data.</p> <p>employees | emp_id | name | manager_id | |--------|------|------------| | 1 | Alice | NULL | | 2 | Bob | 1 | | 3 | Carol | 1 | | 4 | David | 2 |</p> <pre><code>-- Find employees and their managers\nSELECT \n    e.name AS employee,\n    m.name AS manager\nFROM employees e\nLEFT JOIN employees m ON e.manager_id = m.emp_id;\n</code></pre> <p>Result: | employee | manager | |----------|---------| | Alice | NULL | | Bob | Alice | | Carol | Alice | | David | Bob |</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#48-multiple-table-joins","title":"4.8 Multiple Table JOINs","text":"<p>Joining three or more tables:</p> <pre><code>-- Orders with customer names and product names\nSELECT \n    c.name AS customer_name,\n    o.order_id,\n    o.order_date,\n    p.product_name,\n    oi.quantity,\n    p.price,\n    (oi.quantity * p.price) AS line_total\nFROM customers c\nINNER JOIN orders o ON c.customer_id = o.customer_id\nINNER JOIN order_items oi ON o.order_id = oi.order_id\nINNER JOIN products p ON oi.product_id = p.product_id\nORDER BY o.order_date, o.order_id;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#49-join-visual-summary","title":"4.9 JOIN Visual Summary","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          JOIN TYPES SUMMARY                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                          \u2502\n\u2502   INNER JOIN                      LEFT JOIN                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510                   \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510                          \u2502\n\u2502   \u2502  A  \u2502  B  \u2502                   \u2502  A  \u2502  B  \u2502                          \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2534\u2500\u2500\u2510  \u2502                   \u2502  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \u2502                          \u2502\n\u2502   \u2502  \u2502\u2588\u2588\u2588\u2588\u2588\u2502  \u2502                   \u2502  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \u2502                          \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u252c\u2500\u2500\u2518  \u2502                   \u2502  \u2514\u2500\u2500\u252c\u2500\u2500\u2518  \u2502                          \u2502\n\u2502   \u2502     \u2502     \u2502                   \u2502     \u2502     \u2502                          \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518                   \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518                          \u2502\n\u2502   Only matching rows              All of A + matching B                  \u2502\n\u2502                                                                          \u2502\n\u2502   RIGHT JOIN                      FULL OUTER JOIN                        \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510                   \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510                          \u2502\n\u2502   \u2502  A  \u2502  B  \u2502                   \u2502  A  \u2502  B  \u2502                          \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                  \u2502  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2502                          \u2502\n\u2502   \u2502  \u2502  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                  \u2502  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2502                          \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u252c\u2500\u2500\u2518  \u2502                   \u2502  \u2514\u2500\u2500\u252c\u2500\u2500\u2518  \u2502                          \u2502\n\u2502   \u2502     \u2502     \u2502                   \u2502     \u2502     \u2502                          \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518                   \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518                          \u2502\n\u2502   All of B + matching A           All rows from both                     \u2502\n\u2502                                                                          \u2502\n\u2502   CROSS JOIN                      SELF JOIN                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                            \u2502\n\u2502   \u2502  A  \u2502  B  \u2502                   \u2502    A    \u2502                            \u2502\n\u2502   \u2502  \u00d7  \u2502  \u00d7  \u2502                   \u2502  \u250c\u2500\u2500\u2500\u2510  \u2502                            \u2502\n\u2502   \u2502  \u00d7  \u2502  \u00d7  \u2502                   \u2502  \u2502 A \u2502  \u2502                            \u2502\n\u2502   \u2502  \u00d7  \u2502  \u00d7  \u2502                   \u2502  \u2514\u2500\u2500\u2500\u2518  \u2502                            \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                            \u2502\n\u2502   Every combination               Table joined to itself                 \u2502\n\u2502   (A rows \u00d7 B rows)               (hierarchical data)                    \u2502\n\u2502                                                                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#part-5-subqueries-and-ctes","title":"Part 5: Subqueries and CTEs","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#51-subqueries","title":"5.1 Subqueries","text":"<p>A subquery is a query nested inside another query.</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#subquery-in-where","title":"Subquery in WHERE","text":"<pre><code>-- Customers who ordered above average\nSELECT customer_id, name\nFROM customers\nWHERE customer_id IN (\n    SELECT customer_id \n    FROM orders \n    WHERE total_amount &gt; (SELECT AVG(total_amount) FROM orders)\n);\n\n-- Products that have never been ordered\nSELECT product_id, product_name\nFROM products\nWHERE product_id NOT IN (\n    SELECT DISTINCT product_id FROM order_items\n);\n\n-- Using EXISTS (often faster than IN)\nSELECT c.customer_id, c.name\nFROM customers c\nWHERE EXISTS (\n    SELECT 1 FROM orders o \n    WHERE o.customer_id = c.customer_id \n    AND o.total_amount &gt; 500\n);\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#subquery-in-select-scalar-subquery","title":"Subquery in SELECT (Scalar Subquery)","text":"<pre><code>-- Add a column with total order count\nSELECT \n    customer_id,\n    name,\n    (SELECT COUNT(*) FROM orders o WHERE o.customer_id = c.customer_id) AS order_count\nFROM customers c;\n\n-- Compare each product price to category average\nSELECT \n    product_name,\n    price,\n    (SELECT AVG(price) FROM products p2 WHERE p2.category = p1.category) AS category_avg,\n    price - (SELECT AVG(price) FROM products p2 WHERE p2.category = p1.category) AS diff_from_avg\nFROM products p1;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#subquery-in-from-derived-table","title":"Subquery in FROM (Derived Table)","text":"<pre><code>-- Analyze customer spending tiers\nSELECT \n    spending_tier,\n    COUNT(*) AS customer_count,\n    AVG(total_spent) AS avg_spent\nFROM (\n    SELECT \n        customer_id,\n        SUM(total_amount) AS total_spent,\n        CASE \n            WHEN SUM(total_amount) &gt;= 1000 THEN 'High'\n            WHEN SUM(total_amount) &gt;= 500 THEN 'Medium'\n            ELSE 'Low'\n        END AS spending_tier\n    FROM orders\n    GROUP BY customer_id\n) AS customer_spending\nGROUP BY spending_tier;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#52-common-table-expressions-ctes","title":"5.2 Common Table Expressions (CTEs)","text":"<p>CTEs provide a cleaner, more readable way to write complex queries.</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#basic-cte-syntax","title":"Basic CTE Syntax","text":"<pre><code>WITH cte_name AS (\n    -- Your query here\n    SELECT column1, column2 FROM table1\n)\nSELECT * FROM cte_name;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#single-cte-example","title":"Single CTE Example","text":"<pre><code>-- High-value customers CTE\nWITH high_value_customers AS (\n    SELECT \n        customer_id,\n        SUM(total_amount) AS total_spent\n    FROM orders\n    GROUP BY customer_id\n    HAVING SUM(total_amount) &gt; 1000\n)\nSELECT \n    c.name,\n    hvc.total_spent\nFROM customers c\nINNER JOIN high_value_customers hvc ON c.customer_id = hvc.customer_id\nORDER BY hvc.total_spent DESC;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#multiple-ctes","title":"Multiple CTEs","text":"<pre><code>-- Multiple CTEs for complex analysis\nWITH \ncustomer_orders AS (\n    SELECT \n        customer_id,\n        COUNT(*) AS order_count,\n        SUM(total_amount) AS total_spent\n    FROM orders\n    GROUP BY customer_id\n),\ncustomer_categories AS (\n    SELECT \n        customer_id,\n        order_count,\n        total_spent,\n        CASE \n            WHEN total_spent &gt;= 1000 THEN 'Gold'\n            WHEN total_spent &gt;= 500 THEN 'Silver'\n            ELSE 'Bronze'\n        END AS category\n    FROM customer_orders\n)\nSELECT \n    c.name,\n    cc.order_count,\n    cc.total_spent,\n    cc.category\nFROM customers c\nJOIN customer_categories cc ON c.customer_id = cc.customer_id\nORDER BY cc.total_spent DESC;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#part-6-window-functions-analytics-functions","title":"Part 6: Window Functions (Analytics Functions)","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#61-window-function-fundamentals","title":"6.1 Window Function Fundamentals","text":"<p>Window functions perform calculations across a set of rows related to the current row, without collapsing rows like GROUP BY does.</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#syntax-structure","title":"Syntax Structure","text":"<pre><code>function_name(expression) OVER (\n    [PARTITION BY column1, column2, ...]    -- Divides rows into groups\n    [ORDER BY column3, column4, ...]         -- Orders rows within partition\n    [frame_clause]                           -- Defines window frame\n)\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#key-difference-group-by-vs-window-functions","title":"Key Difference: GROUP BY vs Window Functions","text":"<pre><code>-- GROUP BY: Collapses rows\nSELECT customer_id, SUM(amount) AS total\nFROM orders\nGROUP BY customer_id;\n-- Result: One row per customer\n\n-- Window Function: Keeps all rows\nSELECT \n    customer_id,\n    order_id,\n    amount,\n    SUM(amount) OVER (PARTITION BY customer_id) AS customer_total\nFROM orders;\n-- Result: All rows preserved, with running calculation added\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#62-ranking-functions","title":"6.2 Ranking Functions","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#row_number","title":"ROW_NUMBER()","text":"<p>Assigns a unique sequential number to each row within a partition.</p> <pre><code>-- Rank all orders by amount\nSELECT \n    order_id,\n    customer_id,\n    amount,\n    ROW_NUMBER() OVER (ORDER BY amount DESC) AS overall_rank\nFROM orders;\n\n-- Rank orders within each customer\nSELECT \n    order_id,\n    customer_id,\n    amount,\n    ROW_NUMBER() OVER (\n        PARTITION BY customer_id \n        ORDER BY amount DESC\n    ) AS rank_within_customer\nFROM orders;\n</code></pre> <p>Result Example: | order_id | customer_id | amount | rank_within_customer | |----------|-------------|--------|----------------------| | 102 | 1 | 200 | 1 | | 101 | 1 | 150 | 2 | | 105 | 1 | 75 | 3 | | 103 | 2 | 300 | 1 | | 104 | 2 | 100 | 2 |</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#rank","title":"RANK()","text":"<p>Same as ROW_NUMBER, but gives same rank to ties, then skips.</p> <pre><code>SELECT \n    student_name,\n    score,\n    RANK() OVER (ORDER BY score DESC) AS rank\nFROM exam_scores;\n</code></pre> student_name score rank Alice 95 1 Bob 95 1 Carol 90 3 David 85 4"},{"location":"lectures/L2-L3-Relational_Database_Systems/#dense_rank","title":"DENSE_RANK()","text":"<p>Same as RANK, but doesn't skip numbers after ties.</p> <pre><code>SELECT \n    student_name,\n    score,\n    DENSE_RANK() OVER (ORDER BY score DESC) AS dense_rank\nFROM exam_scores;\n</code></pre> student_name score dense_rank Alice 95 1 Bob 95 1 Carol 90 2 David 85 3"},{"location":"lectures/L2-L3-Relational_Database_Systems/#ntilen","title":"NTILE(n)","text":"<p>Divides rows into n approximately equal groups.</p> <pre><code>-- Divide customers into 4 quartiles by total spending\nSELECT \n    customer_id,\n    total_spent,\n    NTILE(4) OVER (ORDER BY total_spent DESC) AS spending_quartile\nFROM customer_totals;\n</code></pre> customer_id total_spent spending_quartile 5 5000 1 3 4500 1 8 3000 2 1 2500 2 ... ... ..."},{"location":"lectures/L2-L3-Relational_Database_Systems/#percent_rank-and-cume_dist","title":"PERCENT_RANK() and CUME_DIST()","text":"<pre><code>SELECT \n    product_name,\n    price,\n    -- Percentile rank (0 to 1)\n    PERCENT_RANK() OVER (ORDER BY price) AS percent_rank,\n    -- Cumulative distribution\n    CUME_DIST() OVER (ORDER BY price) AS cumulative_dist\nFROM products;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#ranking-functions-comparison","title":"Ranking Functions Comparison","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    RANKING FUNCTIONS COMPARISON                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                            \u2502\n\u2502  Data: Scores = [100, 100, 90, 80]                                         \u2502\n\u2502                                                                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\n\u2502  \u2502  Score  \u2502 ROW_NUMBER  \u2502  RANK  \u2502 DENSE_RANK \u2502 NTILE(2)\u2502                 \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524                 \u2502\n\u2502  \u2502   100   \u2502      1      \u2502   1    \u2502     1      \u2502    1    \u2502                 \u2502\n\u2502  \u2502   100   \u2502      2      \u2502   1    \u2502     1      \u2502    1    \u2502                 \u2502\n\u2502  \u2502    90   \u2502      3      \u2502   3    \u2502     2      \u2502    2    \u2502                 \u2502\n\u2502  \u2502    80   \u2502      4      \u2502   4    \u2502     3      \u2502    2    \u2502                 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502\n\u2502                                                                            \u2502\n\u2502  ROW_NUMBER: Always unique (1,2,3,4)                                       \u2502\n\u2502  RANK: Same rank for ties, then skips (1,1,3,4)                            \u2502\n\u2502  DENSE_RANK: Same rank for ties, no skip (1,1,2,3)                         \u2502\n\u2502  NTILE(2): Divides into 2 groups (1,1,2,2)                                 \u2502\n\u2502                                                                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#63-aggregate-window-functions","title":"6.3 Aggregate Window Functions","text":"<p>Use aggregate functions (SUM, AVG, COUNT, etc.) as window functions.</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#running-total","title":"Running Total","text":"<pre><code>-- Cumulative sum of daily revenue\nSELECT \n    order_date,\n    daily_revenue,\n    SUM(daily_revenue) OVER (\n        ORDER BY order_date\n        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n    ) AS running_total\nFROM daily_sales;\n</code></pre> order_date daily_revenue running_total 2025-01-01 100 100 2025-01-02 150 250 2025-01-03 200 450 2025-01-04 75 525"},{"location":"lectures/L2-L3-Relational_Database_Systems/#running-total-by-partition","title":"Running Total by Partition","text":"<pre><code>-- Running total per customer\nSELECT \n    customer_id,\n    order_date,\n    amount,\n    SUM(amount) OVER (\n        PARTITION BY customer_id\n        ORDER BY order_date\n    ) AS customer_running_total\nFROM orders;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#moving-average","title":"Moving Average","text":"<pre><code>-- 7-day moving average\nSELECT \n    order_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY order_date\n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_avg_7day\nFROM daily_sales;\n\n-- 3-period centered moving average\nSELECT \n    order_date,\n    daily_revenue,\n    AVG(daily_revenue) OVER (\n        ORDER BY order_date\n        ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING\n    ) AS centered_avg_3day\nFROM daily_sales;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#count-and-percentage","title":"Count and Percentage","text":"<pre><code>-- Count and percentage within partition\nSELECT \n    category,\n    product_name,\n    price,\n    COUNT(*) OVER (PARTITION BY category) AS category_count,\n    price / SUM(price) OVER (PARTITION BY category) * 100 AS price_pct_of_category\nFROM products;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#64-value-window-functions","title":"6.4 Value Window Functions","text":"<p>Access values from other rows without self-joins.</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#lag-previous-row-value","title":"LAG() - Previous Row Value","text":"<pre><code>-- Get previous day's revenue for comparison\nSELECT \n    order_date,\n    daily_revenue,\n    LAG(daily_revenue, 1) OVER (ORDER BY order_date) AS prev_day_revenue,\n    daily_revenue - LAG(daily_revenue, 1) OVER (ORDER BY order_date) AS day_over_day_change\nFROM daily_sales;\n</code></pre> order_date daily_revenue prev_day_revenue day_over_day_change 2025-01-01 100 NULL NULL 2025-01-02 150 100 50 2025-01-03 120 150 -30 <pre><code>-- LAG with default value for NULLs\nSELECT \n    order_date,\n    daily_revenue,\n    LAG(daily_revenue, 1, 0) OVER (ORDER BY order_date) AS prev_day_revenue\nFROM daily_sales;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#lead-next-row-value","title":"LEAD() - Next Row Value","text":"<pre><code>-- Get next day's revenue\nSELECT \n    order_date,\n    daily_revenue,\n    LEAD(daily_revenue, 1) OVER (ORDER BY order_date) AS next_day_revenue\nFROM daily_sales;\n\n-- Look ahead 7 days\nSELECT \n    order_date,\n    daily_revenue,\n    LEAD(daily_revenue, 7) OVER (ORDER BY order_date) AS revenue_in_7_days\nFROM daily_sales;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#first_value-and-last_value","title":"FIRST_VALUE() and LAST_VALUE()","text":"<pre><code>-- Compare each day to first day of month\nSELECT \n    order_date,\n    daily_revenue,\n    FIRST_VALUE(daily_revenue) OVER (\n        PARTITION BY DATE_TRUNC('month', order_date)\n        ORDER BY order_date\n    ) AS first_day_of_month,\n    daily_revenue - FIRST_VALUE(daily_revenue) OVER (\n        PARTITION BY DATE_TRUNC('month', order_date)\n        ORDER BY order_date\n    ) AS diff_from_first_day\nFROM daily_sales;\n\n-- LAST_VALUE (requires frame specification!)\nSELECT \n    order_date,\n    daily_revenue,\n    LAST_VALUE(daily_revenue) OVER (\n        PARTITION BY DATE_TRUNC('month', order_date)\n        ORDER BY order_date\n        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n    ) AS last_day_of_month\nFROM daily_sales;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#nth_value","title":"NTH_VALUE()","text":"<pre><code>-- Get the 3rd highest value in each partition\nSELECT \n    category,\n    product_name,\n    price,\n    NTH_VALUE(price, 3) OVER (\n        PARTITION BY category\n        ORDER BY price DESC\n        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n    ) AS third_highest_price\nFROM products;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#65-window-frame-specifications","title":"6.5 Window Frame Specifications","text":"<p>The frame clause defines exactly which rows are included in the window.</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#frame-syntax","title":"Frame Syntax","text":"<pre><code>ROWS BETWEEN start_bound AND end_bound\n-- or\nRANGE BETWEEN start_bound AND end_bound\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#bound-options","title":"Bound Options","text":"Bound Meaning <code>UNBOUNDED PRECEDING</code> Start of partition <code>n PRECEDING</code> n rows before current <code>CURRENT ROW</code> Current row <code>n FOLLOWING</code> n rows after current <code>UNBOUNDED FOLLOWING</code> End of partition"},{"location":"lectures/L2-L3-Relational_Database_Systems/#frame-examples","title":"Frame Examples","text":"<pre><code>-- All rows from start to current (running total)\nROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n\n-- Last 7 days including today\nROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n\n-- Centered window (1 before, current, 1 after)\nROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING\n\n-- Entire partition\nROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n\n-- Only future rows (excluding current)\nROWS BETWEEN 1 FOLLOWING AND UNBOUNDED FOLLOWING\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#rows-vs-range","title":"ROWS vs RANGE","text":"<pre><code>-- ROWS: Physical row count\nSELECT \n    order_date,\n    amount,\n    SUM(amount) OVER (\n        ORDER BY order_date\n        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n    ) AS sum_last_3_rows\nFROM orders;\n\n-- RANGE: Logical value range (useful for dates with gaps)\nSELECT \n    order_date,\n    amount,\n    SUM(amount) OVER (\n        ORDER BY order_date\n        RANGE BETWEEN INTERVAL '2 days' PRECEDING AND CURRENT ROW\n    ) AS sum_last_3_days\nFROM orders;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#visual-frame-reference","title":"Visual Frame Reference","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        WINDOW FRAME VISUALIZATION                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502   Partition: [Row1] [Row2] [Row3] [Row4*] [Row5] [Row6] [Row7]               \u2502\n\u2502                                     \u2191                                        \u2502\n\u2502                              Current Row (*)                                 \u2502\n\u2502                                                                              \u2502\n\u2502   ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW:                          \u2502\n\u2502   [Row1] [Row2] [Row3] [Row4*]                                               \u2502\n\u2502   \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524                                               \u2502\n\u2502                                                                              \u2502\n\u2502   ROWS BETWEEN 2 PRECEDING AND CURRENT ROW:                                  \u2502\n\u2502                [Row2] [Row3] [Row4*]                                         \u2502\n\u2502                \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524                                        \u2502\n\u2502                                                                              \u2502\n\u2502   ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING:                                  \u2502\n\u2502                       [Row3] [Row4*] [Row5]                                  \u2502\n\u2502                       \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524                                \u2502\n\u2502                                                                              \u2502\n\u2502   ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING:                          \u2502\n\u2502                              [Row4*] [Row5] [Row6] [Row7]                    \u2502\n\u2502                              \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524                    \u2502\n\u2502                                                                              \u2502\n\u2502   ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING:                  \u2502\n\u2502   [Row1] [Row2] [Row3] [Row4*] [Row5] [Row6] [Row7]                          \u2502\n\u2502   \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524                     \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#66-complete-window-function-examples","title":"6.6 Complete Window Function Examples","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#sales-analysis-dashboard","title":"Sales Analysis Dashboard","text":"<pre><code>WITH daily_metrics AS (\n    SELECT \n        order_date,\n        COUNT(*) AS order_count,\n        SUM(total_amount) AS daily_revenue,\n        AVG(total_amount) AS avg_order_value\n    FROM orders\n    GROUP BY order_date\n)\nSELECT \n    order_date,\n    order_count,\n    daily_revenue,\n    avg_order_value,\n\n    -- Running totals\n    SUM(daily_revenue) OVER (ORDER BY order_date) AS cumulative_revenue,\n    SUM(order_count) OVER (ORDER BY order_date) AS cumulative_orders,\n\n    -- Moving averages\n    AVG(daily_revenue) OVER (\n        ORDER BY order_date \n        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS revenue_ma_7day,\n\n    -- Day-over-day comparison\n    LAG(daily_revenue, 1) OVER (ORDER BY order_date) AS prev_day_revenue,\n    daily_revenue - LAG(daily_revenue, 1) OVER (ORDER BY order_date) AS dod_change,\n\n    -- Week-over-week comparison\n    LAG(daily_revenue, 7) OVER (ORDER BY order_date) AS same_day_last_week,\n\n    -- Percentage of total\n    daily_revenue / SUM(daily_revenue) OVER () * 100 AS pct_of_total,\n\n    -- Ranking\n    RANK() OVER (ORDER BY daily_revenue DESC) AS revenue_rank\n\nFROM daily_metrics\nORDER BY order_date;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#customer-behavior-analysis","title":"Customer Behavior Analysis","text":"<pre><code>SELECT \n    customer_id,\n    order_id,\n    order_date,\n    total_amount,\n\n    -- Order sequence for each customer\n    ROW_NUMBER() OVER (\n        PARTITION BY customer_id \n        ORDER BY order_date\n    ) AS order_sequence,\n\n    -- First and last order amounts\n    FIRST_VALUE(total_amount) OVER (\n        PARTITION BY customer_id \n        ORDER BY order_date\n    ) AS first_order_amount,\n\n    -- Days since previous order\n    order_date - LAG(order_date) OVER (\n        PARTITION BY customer_id \n        ORDER BY order_date\n    ) AS days_since_last_order,\n\n    -- Running total per customer\n    SUM(total_amount) OVER (\n        PARTITION BY customer_id \n        ORDER BY order_date\n    ) AS customer_cumulative_spend,\n\n    -- Customer's total (for % calculation)\n    SUM(total_amount) OVER (PARTITION BY customer_id) AS customer_total,\n\n    -- This order as % of customer total\n    total_amount / SUM(total_amount) OVER (PARTITION BY customer_id) * 100 AS pct_of_customer_total\n\nFROM orders\nORDER BY customer_id, order_date;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#product-performance","title":"Product Performance","text":"<pre><code>SELECT \n    category,\n    product_name,\n    price,\n    units_sold,\n    revenue,\n\n    -- Rank within category\n    RANK() OVER (\n        PARTITION BY category \n        ORDER BY revenue DESC\n    ) AS category_rank,\n\n    -- Top product in category\n    FIRST_VALUE(product_name) OVER (\n        PARTITION BY category \n        ORDER BY revenue DESC\n    ) AS category_leader,\n\n    -- Percentage of category revenue\n    revenue / SUM(revenue) OVER (PARTITION BY category) * 100 AS pct_of_category,\n\n    -- Difference from category average\n    revenue - AVG(revenue) OVER (PARTITION BY category) AS diff_from_category_avg,\n\n    -- Quartile within category\n    NTILE(4) OVER (\n        PARTITION BY category \n        ORDER BY revenue DESC\n    ) AS revenue_quartile\n\nFROM product_sales\nORDER BY category, revenue DESC;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#67-window-functions-summary-table","title":"6.7 Window Functions Summary Table","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      WINDOW FUNCTIONS QUICK REFERENCE                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  RANKING FUNCTIONS                                                          \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  ROW_NUMBER()    Unique sequential number (1,2,3,4...)                      \u2502\n\u2502  RANK()          Same rank for ties, then skip (1,1,3,4...)                 \u2502\n\u2502  DENSE_RANK()    Same rank for ties, no skip (1,1,2,3...)                   \u2502\n\u2502  NTILE(n)        Divide into n equal groups                                 \u2502\n\u2502  PERCENT_RANK()  Percentile rank (0 to 1)                                   \u2502\n\u2502  CUME_DIST()     Cumulative distribution (0 to 1)                           \u2502\n\u2502                                                                             \u2502\n\u2502  VALUE FUNCTIONS                                                            \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  LAG(col, n)     Value from n rows before                                   \u2502\n\u2502  LEAD(col, n)    Value from n rows after                                    \u2502\n\u2502  FIRST_VALUE()   First value in window                                      \u2502\n\u2502  LAST_VALUE()    Last value in window (careful with frame!)                 \u2502\n\u2502  NTH_VALUE(n)    Nth value in window                                        \u2502\n\u2502                                                                             \u2502\n\u2502  AGGREGATE FUNCTIONS (as window functions)                                  \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  SUM()           Running/cumulative sum                                     \u2502\n\u2502  AVG()           Moving/rolling average                                     \u2502\n\u2502  COUNT()         Running count                                              \u2502\n\u2502  MIN() / MAX()   Running min/max                                            \u2502\n\u2502  STDDEV()        Running standard deviation                                 \u2502\n\u2502                                                                             \u2502\n\u2502  FRAME CLAUSES                                                              \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  ROWS BETWEEN ... AND ...                                                   \u2502\n\u2502    UNBOUNDED PRECEDING     Start of partition                               \u2502\n\u2502    n PRECEDING             n rows before                                    \u2502\n\u2502    CURRENT ROW             Current row                                      \u2502\n\u2502    n FOLLOWING             n rows after                                     \u2502\n\u2502    UNBOUNDED FOLLOWING     End of partition                                 \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#part-7-additional-sql-topics","title":"Part 7: Additional SQL Topics","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#71-case-expressions","title":"7.1 CASE Expressions","text":"<pre><code>-- Simple CASE\nSELECT \n    product_name,\n    price,\n    CASE \n        WHEN price &lt; 50 THEN 'Budget'\n        WHEN price &lt; 200 THEN 'Mid-range'\n        WHEN price &lt; 1000 THEN 'Premium'\n        ELSE 'Luxury'\n    END AS price_tier\nFROM products;\n\n-- CASE with aggregation\nSELECT \n    COUNT(CASE WHEN status = 'completed' THEN 1 END) AS completed,\n    COUNT(CASE WHEN status = 'pending' THEN 1 END) AS pending,\n    COUNT(CASE WHEN status = 'cancelled' THEN 1 END) AS cancelled\nFROM orders;\n\n-- CASE in ORDER BY\nSELECT * FROM products\nORDER BY \n    CASE category\n        WHEN 'Electronics' THEN 1\n        WHEN 'Clothing' THEN 2\n        WHEN 'Books' THEN 3\n        ELSE 4\n    END;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#72-string-functions","title":"7.2 String Functions","text":"<pre><code>-- Concatenation\nSELECT CONCAT(first_name, ' ', last_name) AS full_name FROM employees;\nSELECT first_name || ' ' || last_name AS full_name FROM employees;  -- PostgreSQL\n\n-- Case conversion\nSELECT UPPER(name), LOWER(email) FROM customers;\n\n-- Substring\nSELECT SUBSTRING(phone, 1, 3) AS area_code FROM customers;\nSELECT LEFT(name, 1) AS initial FROM customers;\nSELECT RIGHT(ssn, 4) AS last_four FROM employees;\n\n-- Trim whitespace\nSELECT TRIM(name), LTRIM(name), RTRIM(name) FROM customers;\n\n-- Replace\nSELECT REPLACE(phone, '-', '') AS phone_digits FROM customers;\n\n-- Length\nSELECT name, LENGTH(name) AS name_length FROM customers;\n\n-- Position/Find\nSELECT POSITION('@' IN email) AS at_position FROM customers;\nSELECT CHARINDEX('@', email) AS at_position FROM customers;  -- SQL Server\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#73-date-functions","title":"7.3 Date Functions","text":"<pre><code>-- Current date/time\nSELECT CURRENT_DATE, CURRENT_TIME, CURRENT_TIMESTAMP;\nSELECT NOW();  -- PostgreSQL, MySQL\n\n-- Extract parts\nSELECT \n    EXTRACT(YEAR FROM order_date) AS year,\n    EXTRACT(MONTH FROM order_date) AS month,\n    EXTRACT(DAY FROM order_date) AS day,\n    EXTRACT(DOW FROM order_date) AS day_of_week\nFROM orders;\n\n-- Date arithmetic\nSELECT order_date + INTERVAL '30 days' AS due_date FROM orders;\nSELECT order_date - INTERVAL '1 month' AS month_ago FROM orders;\nSELECT order_date + 30 AS due_date FROM orders;  -- MySQL\n\n-- Date truncation\nSELECT DATE_TRUNC('month', order_date) AS month_start FROM orders;\nSELECT DATE_TRUNC('week', order_date) AS week_start FROM orders;\n\n-- Date difference\nSELECT AGE(NOW(), created_at) AS account_age FROM users;  -- PostgreSQL\nSELECT DATEDIFF(NOW(), created_at) AS days_old FROM users;  -- MySQL\n\n-- Formatting\nSELECT TO_CHAR(order_date, 'YYYY-MM-DD') FROM orders;  -- PostgreSQL\nSELECT DATE_FORMAT(order_date, '%Y-%m-%d') FROM orders;  -- MySQL\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#74-null-handling","title":"7.4 NULL Handling","text":"<pre><code>-- COALESCE - returns first non-NULL value\nSELECT COALESCE(phone, email, 'No contact') AS contact FROM customers;\n\n-- NULLIF - returns NULL if values are equal\nSELECT NULLIF(discount, 0) AS discount FROM orders;  -- Avoids division by zero\n\n-- IS NULL / IS NOT NULL\nSELECT * FROM customers WHERE phone IS NULL;\nSELECT * FROM customers WHERE phone IS NOT NULL;\n\n-- NULL-safe comparison (MySQL)\nSELECT * FROM t1 WHERE col &lt;=&gt; NULL;\n\n-- IFNULL (MySQL) / NVL (Oracle)\nSELECT IFNULL(phone, 'N/A') FROM customers;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#75-data-manipulation-insert-update-delete","title":"7.5 Data Manipulation (INSERT, UPDATE, DELETE)","text":"<pre><code>-- INSERT single row\nINSERT INTO customers (name, email, city)\nVALUES ('John Doe', 'john@email.com', 'NYC');\n\n-- INSERT multiple rows\nINSERT INTO customers (name, email, city)\nVALUES \n    ('Jane Smith', 'jane@email.com', 'LA'),\n    ('Bob Wilson', 'bob@email.com', 'Chicago');\n\n-- INSERT from SELECT\nINSERT INTO archived_orders\nSELECT * FROM orders WHERE order_date &lt; '2024-01-01';\n\n-- UPDATE\nUPDATE customers \nSET city = 'San Francisco'\nWHERE customer_id = 1;\n\n-- UPDATE with calculation\nUPDATE products\nSET price = price * 1.1\nWHERE category = 'Electronics';\n\n-- UPDATE with JOIN\nUPDATE orders o\nSET o.status = 'archived'\nFROM customers c\nWHERE o.customer_id = c.customer_id\n  AND c.status = 'inactive';\n\n-- DELETE\nDELETE FROM orders WHERE order_id = 101;\n\n-- DELETE with condition\nDELETE FROM orders WHERE order_date &lt; '2020-01-01';\n\n-- DELETE all (but keep table structure)\nDELETE FROM temp_table;\nTRUNCATE TABLE temp_table;  -- Faster, no logging\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#76-indexing","title":"7.6 Indexing","text":"<pre><code>-- Create index\nCREATE INDEX idx_customer_email ON customers(email);\n\n-- Create composite index\nCREATE INDEX idx_order_customer_date ON orders(customer_id, order_date);\n\n-- Create unique index\nCREATE UNIQUE INDEX idx_email_unique ON customers(email);\n\n-- Create partial index (PostgreSQL)\nCREATE INDEX idx_active_orders ON orders(order_date) \nWHERE status = 'active';\n\n-- Drop index\nDROP INDEX idx_customer_email;\n\n-- Show indexes\nSHOW INDEX FROM customers;  -- MySQL\n\\di customers  -- PostgreSQL\n</code></pre> <p>When to Create Indexes: - Columns frequently used in WHERE clauses - Columns used in JOIN conditions - Columns used in ORDER BY - Foreign key columns</p> <p>When NOT to Index: - Small tables (full scan is faster) - Columns with low cardinality (few unique values) - Frequently updated columns - Wide columns (large text fields)</p>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#77-views","title":"7.7 Views","text":"<pre><code>-- Create view\nCREATE VIEW customer_order_summary AS\nSELECT \n    c.customer_id,\n    c.name,\n    COUNT(o.order_id) AS total_orders,\n    SUM(o.total_amount) AS total_spent,\n    AVG(o.total_amount) AS avg_order_value\nFROM customers c\nLEFT JOIN orders o ON c.customer_id = o.customer_id\nGROUP BY c.customer_id, c.name;\n\n-- Use view like a table\nSELECT * FROM customer_order_summary WHERE total_orders &gt; 10;\n\n-- Create or replace view\nCREATE OR REPLACE VIEW customer_order_summary AS ...;\n\n-- Drop view\nDROP VIEW customer_order_summary;\n\n-- Materialized view (PostgreSQL) - physically stores results\nCREATE MATERIALIZED VIEW mv_daily_sales AS\nSELECT DATE(order_date) AS date, SUM(total_amount) AS revenue\nFROM orders GROUP BY DATE(order_date);\n\n-- Refresh materialized view\nREFRESH MATERIALIZED VIEW mv_daily_sales;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#78-transactions","title":"7.8 Transactions","text":"<pre><code>-- Basic transaction\nBEGIN;  -- or START TRANSACTION\n\nUPDATE accounts SET balance = balance - 100 WHERE account_id = 'A';\nUPDATE accounts SET balance = balance + 100 WHERE account_id = 'B';\n\nCOMMIT;  -- Save changes\n\n-- Rollback on error\nBEGIN;\n\nUPDATE accounts SET balance = balance - 100 WHERE account_id = 'A';\n-- Something goes wrong...\nROLLBACK;  -- Undo all changes\n\n-- Savepoints\nBEGIN;\n\nUPDATE accounts SET balance = balance - 100 WHERE account_id = 'A';\nSAVEPOINT after_debit;\n\nUPDATE accounts SET balance = balance + 100 WHERE account_id = 'B';\n-- Problem with B...\nROLLBACK TO after_debit;  -- Keep A's changes, undo B\n\nCOMMIT;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#part-8-query-execution-order","title":"Part 8: Query Execution Order","text":"<p>Understanding the logical order of SQL clause execution helps write correct queries.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      SQL LOGICAL EXECUTION ORDER                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502   Written Order:                  Execution Order:                           \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                           \u2502\n\u2502   1. SELECT                       1. FROM / JOIN                             \u2502\n\u2502   2. FROM                         2. WHERE                                   \u2502\n\u2502   3. JOIN                         3. GROUP BY                                \u2502\n\u2502   4. WHERE                        4. HAVING                                  \u2502\n\u2502   5. GROUP BY                     5. SELECT                                  \u2502\n\u2502   6. HAVING                       6. DISTINCT                                \u2502\n\u2502   7. ORDER BY                     7. ORDER BY                                \u2502\n\u2502   8. LIMIT                        8. LIMIT / OFFSET                          \u2502\n\u2502                                                                              \u2502\n\u2502   This is why:                                                               \u2502\n\u2502   \u2022 Can't use SELECT aliases in WHERE (SELECT runs after)                    \u2502\n\u2502   \u2022 CAN use SELECT aliases in ORDER BY (ORDER BY runs after SELECT)          \u2502\n\u2502   \u2022 Can't use aggregate functions in WHERE (GROUP BY runs after)             \u2502\n\u2502   \u2022 CAN use aggregate functions in HAVING (HAVING runs after GROUP BY)       \u2502\n\u2502                                                                              \u2502\n\u2502   Example:                                                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502   \u2502  SELECT customer_id, SUM(amount) AS total     -- Runs 5th          \u2502    \u2502\n\u2502   \u2502  FROM orders                                   -- Runs 1st          \u2502    \u2502\n\u2502   \u2502  WHERE order_date &gt;= '2025-01-01'             -- Runs 2nd          \u2502    \u2502\n\u2502   \u2502  GROUP BY customer_id                          -- Runs 3rd          \u2502    \u2502\n\u2502   \u2502  HAVING SUM(amount) &gt; 1000                     -- Runs 4th          \u2502    \u2502\n\u2502   \u2502  ORDER BY total DESC                           -- Runs 6th          \u2502    \u2502\n\u2502   \u2502  LIMIT 10;                                     -- Runs 7th          \u2502    \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#quick-reference-card","title":"Quick Reference Card","text":""},{"location":"lectures/L2-L3-Relational_Database_Systems/#sql-statement-templates","title":"SQL Statement Templates","text":"<pre><code>-- Basic Query\nSELECT columns FROM table WHERE condition;\n\n-- Aggregation\nSELECT group_col, AGG(col) FROM table GROUP BY group_col HAVING condition;\n\n-- Join\nSELECT * FROM t1 [INNER|LEFT|RIGHT|FULL] JOIN t2 ON t1.key = t2.key;\n\n-- Subquery\nSELECT * FROM t1 WHERE col IN (SELECT col FROM t2);\n\n-- CTE\nWITH cte AS (SELECT ...) SELECT * FROM cte;\n\n-- Window Function\nSELECT col, FUNC() OVER (PARTITION BY col ORDER BY col ROWS BETWEEN ...) FROM t;\n\n-- Insert\nINSERT INTO table (cols) VALUES (vals);\n\n-- Update  \nUPDATE table SET col = val WHERE condition;\n\n-- Delete\nDELETE FROM table WHERE condition;\n</code></pre>"},{"location":"lectures/L2-L3-Relational_Database_Systems/#common-patterns","title":"Common Patterns","text":"<pre><code>-- Top N per group\nWITH ranked AS (\n    SELECT *, ROW_NUMBER() OVER (PARTITION BY group_col ORDER BY sort_col DESC) AS rn\n    FROM table\n)\nSELECT * FROM ranked WHERE rn &lt;= N;\n\n-- Running total\nSELECT *, SUM(amount) OVER (ORDER BY date) AS running_total FROM table;\n\n-- Year-over-year comparison\nSELECT \n    current_year.*,\n    LAG(metric, 12) OVER (ORDER BY month) AS same_month_last_year\nFROM monthly_data current_year;\n\n-- Percent of total\nSELECT *, amount / SUM(amount) OVER () * 100 AS pct_of_total FROM table;\n\n-- Find duplicates\nSELECT col, COUNT(*) FROM table GROUP BY col HAVING COUNT(*) &gt; 1;\n\n-- Find gaps in sequence\nSELECT id + 1 AS gap_start\nFROM table t1\nWHERE NOT EXISTS (SELECT 1 FROM table t2 WHERE t2.id = t1.id + 1);\n</code></pre>"},{"location":"lectures/Lecture01_Foundations/","title":"Lecture 01: Data as a Building Block","text":""},{"location":"lectures/Lecture01_Foundations/#part-i-foundations-of-data-engineering","title":"PART I: FOUNDATIONS OF DATA ENGINEERING","text":""},{"location":"lectures/Lecture01_Foundations/#chapter-1-the-data-lifecycle-understanding-the-complete-journey","title":"Chapter 1: The Data Lifecycle \u2014 Understanding the Complete Journey","text":"<p>\"Data is a precious thing and will last longer than the systems themselves.\" \u2014 Tim Berners-Lee, inventor of the World Wide Web</p>"},{"location":"lectures/Lecture01_Foundations/#11-introduction-why-data-engineering-matters","title":"1.1 Introduction: Why Data Engineering Matters","text":"<p>In the modern era of artificial intelligence and machine learning, there is a common misconception that the magic happens in the models. Data scientists spend years mastering sophisticated algorithms, neural network architectures, and statistical methods. Yet, when they enter the workforce, they discover an uncomfortable truth: approximately 80% of their time is spent not on modeling, but on finding, cleaning, and preparing data.</p> <p>This reality has given rise to a fundamental shift in how we think about building intelligent systems. As Andrew Ng, co-founder of Google Brain and former Chief Scientist at Baidu, has emphasized through his advocacy for \"data-centric AI\": the quality of your data often matters more than the sophistication of your model. A simple logistic regression trained on excellent, well-curated data will frequently outperform a complex deep learning model trained on messy, poorly understood data.</p> <p>The emerging field of data-centric AI \"emphasizes the systematic engineering of data to build AI systems, shifting our focus from model to data. It is important to note that 'data-centric' differs fundamentally from 'data-driven', as the latter only emphasizes the use of data to guide AI development, which typically still centers on models\" (Zha et al., 2023).</p> <p>This chapter introduces you to the complete data lifecycle\u2014the journey that data takes from its point of origin to its ultimate use in analysis, machine learning, and decision-making. Understanding this lifecycle transforms you from a passive consumer of datasets into an informed practitioner who can:</p> <ul> <li>Trace the provenance of any dataset and understand its limitations</li> <li>Identify where data quality issues originate</li> <li>Design better features because you understand the source systems</li> <li>Communicate effectively with data engineers and infrastructure teams</li> <li>Build your own data pipelines when necessary</li> </ul>"},{"location":"lectures/Lecture01_Foundations/#12-the-data-lifecycle-a-conceptual-framework","title":"1.2 The Data Lifecycle: A Conceptual Framework","text":"<p>Data does not simply appear in a clean CSV file ready for analysis. It flows through a series of stages, each with its own challenges, tools, and best practices. Understanding this flow\u2014the data lifecycle\u2014provides the mental framework necessary for working effectively with data at any scale.</p>"},{"location":"lectures/Lecture01_Foundations/#121-the-eight-stages-of-the-data-lifecycle","title":"1.2.1 The Eight Stages of the Data Lifecycle","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                                                                  \u2502\n\u2502                         THE DATA LIFECYCLE                                       \u2502\n\u2502                                                                                  \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502     \u2502 GENERATE \u2502\u2500\u2500\u2500\u25b6\u2502 COLLECT  \u2502\u2500\u2500\u2500\u25b6\u2502  STORE   \u2502\u2500\u2500\u2500\u25b6\u2502TRANSFORM \u2502               \u2502\n\u2502     \u2502          \u2502    \u2502 (Ingest) \u2502    \u2502 (Persist)\u2502    \u2502 (Process)\u2502               \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502                                                            \u2502                    \u2502\n\u2502                                                            \u25bc                    \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n\u2502     \u2502 ARCHIVE  \u2502\u25c0\u2500\u2500\u2500\u2502 MAINTAIN \u2502\u25c0\u2500\u2500\u2500\u2502  SERVE   \u2502\u25c0\u2500\u2500\u2500\u2502 ANALYZE  \u2502               \u2502\n\u2502     \u2502 (Retire) \u2502    \u2502 (Operate)\u2502    \u2502 (Deliver)\u2502    \u2502 (Consume)\u2502               \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n\u2502                                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Let us examine each stage in detail.</p>"},{"location":"lectures/Lecture01_Foundations/#122-stage-1-generation-where-data-originates","title":"1.2.2 Stage 1: Generation \u2014 Where Data Originates","text":"<p>Every piece of data begins somewhere. Understanding the origin of data\u2014its provenance\u2014is essential for assessing its reliability, understanding its structure, and anticipating its limitations.</p>"},{"location":"lectures/Lecture01_Foundations/#sources-of-data-generation","title":"Sources of Data Generation","text":"Source Category Examples Characteristics Transactional Systems Point-of-sale systems, banking transactions, e-commerce orders Highly structured, real-time, mission-critical accuracy User Interactions Website clicks, mobile app events, search queries Semi-structured, extremely high volume, behavioral Operational Systems CRM records, ERP data, inventory management Structured, business-process driven IoT and Sensors Temperature readings, GPS coordinates, machine telemetry Time-series, continuous streams, potentially noisy Third-Party Sources APIs (weather, financial markets, social media), purchased datasets Various formats, rate-limited, external dependencies User-Generated Content Reviews, comments, uploaded files, form submissions Unstructured or semi-structured, requires validation Machine-Generated Logs Application logs, server metrics, error reports Semi-structured, high volume, essential for debugging"},{"location":"lectures/Lecture01_Foundations/#the-importance-of-understanding-data-generation","title":"The Importance of Understanding Data Generation","text":"<p>When you receive a dataset, asking \"where did this data come from?\" is not merely an academic exercise. The generation context determines:</p> <ul> <li>Data quality: Manual entry systems have different error profiles than automated sensors</li> <li>Timeliness: Real-time systems provide current data; batch extracts may be hours or days old</li> <li>Completeness: Some systems capture everything; others sample or aggregate</li> <li>Bias: The mechanism of data collection often introduces systematic biases</li> </ul> <p>Key Insight: The most sophisticated analysis cannot overcome fundamental flaws introduced at the data generation stage. Always trace your data back to its source.</p>"},{"location":"lectures/Lecture01_Foundations/#123-stage-2-collection-bringing-data-into-your-systems","title":"1.2.3 Stage 2: Collection \u2014 Bringing Data Into Your Systems","text":"<p>Once data is generated, it must be captured and brought into your data infrastructure. This process\u2014data ingestion\u2014presents its own set of challenges and design decisions.</p>"},{"location":"lectures/Lecture01_Foundations/#batch-vs-streaming-ingestion","title":"Batch vs. Streaming Ingestion","text":"<p>The two fundamental paradigms for data collection are batch processing and stream processing:</p> <p>Batch Ingestion <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Source    \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Scheduled Job     \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Storage   \u2502\n\u2502   System    \u2502     \u2502 (hourly/daily/weekly)\u2502    \u2502   System    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Batch ingestion collects data at scheduled intervals. A nightly job might extract all new records from a production database, transform them, and load them into a data warehouse. This approach is:</p> <ul> <li>Simpler to implement and debug</li> <li>More efficient for large volumes (economies of scale)</li> <li>Acceptable when real-time data is not required</li> <li>Easier to ensure data consistency</li> </ul> <p>Stream Ingestion <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Source    \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Continuous        \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Storage   \u2502\n\u2502   System    \u2502     \u2502   Stream Processor  \u2502     \u2502   System    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Stream ingestion processes data continuously as it arrives. User click events might flow through Apache Kafka into a real-time analytics system within milliseconds. This approach is:</p> <ul> <li>Essential when freshness matters (fraud detection, real-time recommendations)</li> <li>More complex to implement correctly</li> <li>Requires careful handling of late-arriving data</li> <li>Demands robust error handling for continuous operation</li> </ul>"},{"location":"lectures/Lecture01_Foundations/#common-ingestion-patterns","title":"Common Ingestion Patterns","text":"Pattern Description Use Case Full Load Extract entire dataset each time Small reference tables, initial loads Incremental Load Extract only new or changed records Large transactional tables Change Data Capture (CDC) Capture individual insert/update/delete operations Real-time replication, audit trails Event Streaming Continuous flow of discrete events User behavior tracking, IoT data"},{"location":"lectures/Lecture01_Foundations/#124-stage-3-storage-persisting-data-for-future-use","title":"1.2.4 Stage 3: Storage \u2014 Persisting Data for Future Use","text":"<p>Once collected, data must be stored in systems appropriate for its structure, volume, and intended use. The choice of storage system has profound implications for cost, query performance, and analytical capabilities.</p>"},{"location":"lectures/Lecture01_Foundations/#the-storage-landscape","title":"The Storage Landscape","text":"<p>Modern data infrastructure typically includes multiple storage systems, each optimized for different purposes:</p> <p>Databases are optimized for transactional operations\u2014reading and writing individual records quickly and reliably. They store the current state of operational data.</p> <p>Data Warehouses are optimized for analytical queries\u2014aggregating millions of records to answer business questions. They store historical data in structured, pre-defined schemas.</p> <p>Data Lakes store raw data in its native format, without requiring a pre-defined schema. They accommodate structured, semi-structured, and unstructured data at massive scale.</p> <p>As the MongoDB documentation explains: \"A database stores the current data required to power an application. A data warehouse stores current and historical data for one or more systems in a predefined and fixed schema for the purpose of analyzing the data. Data lakes store data in their raw form\" (MongoDB, 2024).</p> <p>We will explore these storage systems in depth in Chapter 3.</p>"},{"location":"lectures/Lecture01_Foundations/#125-stage-4-transformation-making-data-useful","title":"1.2.5 Stage 4: Transformation \u2014 Making Data Useful","text":"<p>Raw data is rarely suitable for analysis. The transformation stage encompasses all the processing required to convert raw data into analysis-ready datasets.</p>"},{"location":"lectures/Lecture01_Foundations/#the-transformation-spectrum","title":"The Transformation Spectrum","text":"<p>Transformations range from simple to complex:</p> Transformation Type Examples Complexity Cleaning Removing duplicates, handling null values, correcting typos Basic Standardization Consistent date formats, normalized text case, unified units Basic Validation Enforcing data types, range checks, referential integrity Moderate Enrichment Adding derived fields, joining with reference data Moderate Aggregation Summarizing transactions by day/week/month Moderate Feature Engineering Creating ML features from raw signals Advanced Complex Business Logic Multi-step calculations, conditional transformations Advanced"},{"location":"lectures/Lecture01_Foundations/#the-etl-vs-elt-paradigm","title":"The ETL vs. ELT Paradigm","text":"<p>Historically, transformations occurred during the data movement process itself\u2014Extract, Transform, Load (ETL). Data was extracted from sources, transformed in a dedicated processing system, and then loaded into the destination.</p> <p>Modern cloud data warehouses have enabled a different approach\u2014Extract, Load, Transform (ELT). Raw data is loaded directly into the destination, and transformations occur within the powerful processing engines of cloud warehouses like Snowflake, BigQuery, or Redshift.</p> <p>We will examine these paradigms thoroughly in Chapter 6.</p>"},{"location":"lectures/Lecture01_Foundations/#126-stage-5-analysis-extracting-insights","title":"1.2.6 Stage 5: Analysis \u2014 Extracting Insights","text":"<p>The analysis stage is where data scientists typically enter the picture. This encompasses:</p> <ul> <li>Exploratory Data Analysis (EDA): Understanding distributions, relationships, and anomalies</li> <li>Statistical Analysis: Hypothesis testing, significance testing, causal inference</li> <li>Machine Learning: Building predictive and prescriptive models</li> <li>Business Intelligence: Creating reports, dashboards, and visualizations</li> </ul> <p>While this stage is the traditional focus of data science education, its success depends entirely on the quality of the preceding stages.</p>"},{"location":"lectures/Lecture01_Foundations/#127-stage-6-serving-delivering-value","title":"1.2.7 Stage 6: Serving \u2014 Delivering Value","text":"<p>Analysis has no value unless its results reach decision-makers. The serving stage delivers insights through:</p> <ul> <li>Dashboards and Reports: Self-service access to metrics and KPIs</li> <li>APIs: Programmatic access for applications</li> <li>Embedded Analytics: Insights integrated into operational systems</li> <li>ML Model Predictions: Real-time or batch scoring</li> <li>Alerts and Notifications: Proactive communication of important changes</li> </ul>"},{"location":"lectures/Lecture01_Foundations/#128-stage-7-maintenance-ensuring-reliability","title":"1.2.8 Stage 7: Maintenance \u2014 Ensuring Reliability","text":"<p>Data systems require ongoing care to remain reliable and trustworthy:</p> <ul> <li>Monitoring: Tracking data freshness, quality metrics, and system health</li> <li>Alerting: Automated notification of anomalies or failures</li> <li>Documentation: Maintaining accurate metadata and lineage information</li> <li>Evolution: Updating systems as requirements change</li> <li>Incident Response: Diagnosing and resolving data issues</li> </ul>"},{"location":"lectures/Lecture01_Foundations/#129-stage-8-archival-managing-the-end-of-life","title":"1.2.9 Stage 8: Archival \u2014 Managing the End of Life","text":"<p>Data does not live forever. The archival stage addresses:</p> <ul> <li>Retention Policies: How long different data types must be kept</li> <li>Cold Storage: Moving infrequently accessed data to cheaper storage tiers</li> <li>Deletion: Permanently removing data per policy or regulation</li> <li>Compliance: Meeting legal requirements like GDPR's \"right to erasure\"</li> </ul>"},{"location":"lectures/Lecture01_Foundations/#13-roles-in-the-data-ecosystem","title":"1.3 Roles in the Data Ecosystem","text":"<p>The data lifecycle involves multiple specialized roles. Understanding these roles\u2014and how they interact\u2014improves collaboration and helps you identify when to seek expertise.</p>"},{"location":"lectures/Lecture01_Foundations/#131-the-core-data-roles","title":"1.3.1 The Core Data Roles","text":"Role Primary Responsibility Key Skills Tools Data Engineer Build and maintain data infrastructure Python, SQL, distributed systems Spark, Airflow, Kafka, Cloud platforms Data Scientist Extract insights and build models Statistics, ML, programming Python, R, SQL, ML frameworks Data Analyst Answer business questions with data SQL, visualization, business acumen SQL, Tableau, Excel, Looker Analytics Engineer Transform data for analysis SQL, data modeling, software engineering dbt, SQL, Git ML Engineer Deploy and scale ML systems Software engineering, MLOps Docker, Kubernetes, MLflow Data Architect Design overall data strategy Systems design, governance Architecture tools, cloud platforms"},{"location":"lectures/Lecture01_Foundations/#132-the-evolving-boundaries","title":"1.3.2 The Evolving Boundaries","text":"<p>These roles are not rigid silos. In practice:</p> <ul> <li>Data scientists increasingly need data engineering skills to be self-sufficient</li> <li>Data engineers benefit from understanding analytical use cases</li> <li>Analytics engineers emerged to bridge the gap between engineering and analysis</li> <li>Small teams often combine multiple roles into \"full-stack\" data practitioners</li> </ul> <p>For Data Scientists: Developing data engineering competency makes you dramatically more effective. You can prototype pipelines, debug data issues, and work independently on smaller projects\u2014while collaborating more effectively with specialists on larger ones.</p>"},{"location":"lectures/Lecture01_Foundations/#14-event-tracking-and-event-driven-architecture","title":"1.4 Event Tracking and Event-Driven Architecture","text":"<p>In the modern data landscape, events are the fundamental unit of behavioral data. Understanding event tracking is essential for any data scientist working with user behavior, product analytics, or real-time systems.</p>"},{"location":"lectures/Lecture01_Foundations/#141-what-is-an-event","title":"1.4.1 What is an Event?","text":"<p>An event is a record of something that happened at a specific point in time. Unlike a database record that represents the current state of an entity, an event captures a discrete occurrence.</p> <p>The anatomy of an event:</p> <pre><code>EVENT = WHAT happened + WHEN it happened + WHO did it + WHERE + CONTEXT\n</code></pre> <p>Consider this example of a well-structured event:</p> <pre><code>{\n  \"event_id\": \"evt_8f14e45f-ceea-367a-a27d-f0c12e45bc\",\n  \"event_name\": \"product_added_to_cart\",\n  \"timestamp\": \"2025-11-29T14:32:15.123Z\",\n\n  \"user_id\": \"usr_abc123\",\n  \"anonymous_id\": \"anon_device_fingerprint_xyz\",\n  \"session_id\": \"sess_789xyz\",\n\n  \"properties\": {\n    \"product_id\": \"prod_456\",\n    \"product_name\": \"Wireless Noise-Canceling Headphones\",\n    \"price\": 249.99,\n    \"currency\": \"USD\",\n    \"quantity\": 1,\n    \"category\": \"Electronics/Audio\",\n    \"brand\": \"SoundMax\"\n  },\n\n  \"context\": {\n    \"page_url\": \"https://shop.example.com/products/wireless-headphones\",\n    \"page_title\": \"Wireless Headphones - SoundMax\",\n    \"referrer\": \"https://www.google.com/search?q=best+wireless+headphones\",\n    \"device\": {\n      \"type\": \"mobile\",\n      \"os\": \"iOS\",\n      \"os_version\": \"17.1\",\n      \"browser\": \"Safari\",\n      \"screen_width\": 390,\n      \"screen_height\": 844\n    },\n    \"location\": {\n      \"country\": \"United States\",\n      \"region\": \"California\",\n      \"city\": \"San Francisco\",\n      \"timezone\": \"America/Los_Angeles\"\n    },\n    \"campaign\": {\n      \"source\": \"google\",\n      \"medium\": \"cpc\",\n      \"campaign\": \"holiday_sale_2025\",\n      \"term\": \"wireless headphones\"\n    }\n  },\n\n  \"metadata\": {\n    \"sent_at\": \"2025-11-29T14:32:15.456Z\",\n    \"received_at\": \"2025-11-29T14:32:15.789Z\",\n    \"sdk_version\": \"2.5.1\",\n    \"library\": \"analytics.js\"\n  }\n}\n</code></pre>"},{"location":"lectures/Lecture01_Foundations/#142-the-event-driven-architecture","title":"1.4.2 The Event-Driven Architecture","text":"<p>Events flow through a system architecture designed to capture, transport, and process them reliably at scale.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         EVENT-DRIVEN ARCHITECTURE                                \u2502\n\u2502                                                                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                          EVENT PRODUCERS                                    \u2502 \u2502\n\u2502  \u2502                                                                             \u2502 \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502 \u2502\n\u2502  \u2502   \u2502   Web   \u2502   \u2502 Mobile  \u2502   \u2502 Backend \u2502   \u2502   IoT   \u2502   \u2502  Third  \u2502     \u2502 \u2502\n\u2502  \u2502   \u2502  Apps   \u2502   \u2502  Apps   \u2502   \u2502Services \u2502   \u2502 Devices \u2502   \u2502  Party  \u2502     \u2502 \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518     \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502           \u2502             \u2502             \u2502             \u2502             \u2502            \u2502\n\u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2502                                \u2502                                                \u2502\n\u2502                                \u25bc                                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                       EVENT COLLECTION LAYER                                \u2502 \u2502\n\u2502  \u2502                                                                             \u2502 \u2502\n\u2502  \u2502   \u2022 SDK/Tracking Libraries (Segment, Amplitude, Mixpanel, custom)          \u2502 \u2502\n\u2502  \u2502   \u2022 API Gateways and Webhook Receivers                                      \u2502 \u2502\n\u2502  \u2502   \u2022 Validation, Enrichment, and Routing                                     \u2502 \u2502\n\u2502  \u2502                                                                             \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                       \u2502                                         \u2502\n\u2502                                       \u25bc                                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502                       EVENT STREAMING LAYER                                 \u2502 \u2502\n\u2502  \u2502                                                                             \u2502 \u2502\n\u2502  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502  \u2502   \u2502                    MESSAGE QUEUE / EVENT BUS                          \u2502 \u2502 \u2502\n\u2502  \u2502   \u2502                                                                       \u2502 \u2502 \u2502\n\u2502  \u2502   \u2502    Apache Kafka  \u2022  Amazon Kinesis  \u2022  Google Pub/Sub  \u2022  RabbitMQ   \u2502 \u2502 \u2502\n\u2502  \u2502   \u2502                                                                       \u2502 \u2502 \u2502\n\u2502  \u2502   \u2502    \u2022 Durability: Events persisted to disk                            \u2502 \u2502 \u2502\n\u2502  \u2502   \u2502    \u2022 Scalability: Partitioned for parallel processing                \u2502 \u2502 \u2502\n\u2502  \u2502   \u2502    \u2022 Decoupling: Producers and consumers operate independently       \u2502 \u2502 \u2502\n\u2502  \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                       \u2502                                         \u2502\n\u2502           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502           \u2502                           \u2502                           \u2502             \u2502\n\u2502           \u25bc                           \u25bc                           \u25bc             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502  \u2502   REAL-TIME     \u2502       \u2502     BATCH       \u2502       \u2502    DERIVED      \u2502       \u2502\n\u2502  \u2502   PROCESSING    \u2502       \u2502    STORAGE      \u2502       \u2502     DATA        \u2502       \u2502\n\u2502  \u2502                 \u2502       \u2502                 \u2502       \u2502                 \u2502       \u2502\n\u2502  \u2502 \u2022 Live dashboards\u2502      \u2502 \u2022 Data Lake     \u2502       \u2502 \u2022 Data Warehouse\u2502       \u2502\n\u2502  \u2502 \u2022 Alerting      \u2502       \u2502 \u2022 Raw event     \u2502       \u2502 \u2022 Aggregated    \u2502       \u2502\n\u2502  \u2502 \u2022 Real-time ML  \u2502       \u2502   archive       \u2502       \u2502   tables        \u2502       \u2502\n\u2502  \u2502 \u2022 Fraud detection\u2502      \u2502 \u2022 Parquet files \u2502       \u2502 \u2022 ML features   \u2502       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502                                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"lectures/Lecture01_Foundations/#143-designing-an-event-taxonomy","title":"1.4.3 Designing an Event Taxonomy","text":"<p>A well-designed event taxonomy\u2014the organized catalog of all events your system tracks\u2014is crucial for maintainability and analytical utility.</p>"},{"location":"lectures/Lecture01_Foundations/#event-naming-conventions","title":"Event Naming Conventions","text":"<p>Consistency in naming enables self-service analytics and reduces confusion:</p> <p>Recommended Pattern: <code>object_action</code></p> <pre><code>\u2713 product_viewed\n\u2713 product_added_to_cart\n\u2713 cart_viewed\n\u2713 checkout_started\n\u2713 checkout_step_completed\n\u2713 order_completed\n\u2713 order_refunded\n\u2713 user_signed_up\n\u2713 user_logged_in\n\u2713 subscription_started\n\u2713 subscription_cancelled\n</code></pre> <p>Patterns to Avoid:</p> <pre><code>\u2717 click                      (too generic)\n\u2717 event_1, event_2           (meaningless)\n\u2717 productAddedToCart         (inconsistent casing)\n\u2717 add_to_cart_button_clicked_on_product_detail_page  (too specific)\n\u2717 tracking_event             (redundant)\n</code></pre>"},{"location":"lectures/Lecture01_Foundations/#event-categories","title":"Event Categories","text":"<p>Organizing events into categories improves discoverability:</p> Category Purpose Example Events Acquisition How users arrive <code>campaign_clicked</code>, <code>referral_received</code> Activation First value moments <code>user_signed_up</code>, <code>onboarding_completed</code> Engagement Core product usage <code>feature_used</code>, <code>content_viewed</code> Conversion Revenue events <code>subscription_started</code>, <code>purchase_completed</code> Retention Return behavior <code>user_returned</code>, <code>streak_maintained</code> System Technical events <code>error_occurred</code>, <code>page_loaded</code>"},{"location":"lectures/Lecture01_Foundations/#144-event-properties-and-context","title":"1.4.4 Event Properties and Context","text":"<p>The value of an event lies not just in knowing it occurred, but in the rich context captured alongside it.</p>"},{"location":"lectures/Lecture01_Foundations/#properties-vs-context","title":"Properties vs. Context","text":"<p>Properties are specific to the event type:</p> <pre><code>// For \"product_added_to_cart\"\n\"properties\": {\n  \"product_id\": \"prod_456\",\n  \"product_name\": \"Wireless Headphones\",\n  \"price\": 249.99,\n  \"quantity\": 1,\n  \"category\": \"Electronics\"\n}\n</code></pre> <p>Context is captured automatically for all events:</p> <pre><code>// Same for every event\n\"context\": {\n  \"page_url\": \"...\",\n  \"device\": { \"type\": \"mobile\", \"os\": \"iOS\" },\n  \"location\": { \"country\": \"US\" },\n  \"campaign\": { \"source\": \"google\", \"medium\": \"cpc\" }\n}\n</code></pre>"},{"location":"lectures/Lecture01_Foundations/#identity-resolution","title":"Identity Resolution","text":"<p>Users interact with products across devices and sessions, often before creating an account. Event systems must handle:</p> <ul> <li>Anonymous ID: Device or browser identifier before login</li> <li>User ID: Authenticated identifier after login</li> <li>Session ID: Groups events within a single visit</li> <li>Identity Stitching: Connecting anonymous activity to known users after authentication</li> </ul> <pre><code>// Before login\n{\n  \"event_name\": \"product_viewed\",\n  \"anonymous_id\": \"anon_device_123\",\n  \"user_id\": null\n}\n\n// After login (same session)\n{\n  \"event_name\": \"user_logged_in\",\n  \"anonymous_id\": \"anon_device_123\",\n  \"user_id\": \"usr_abc456\"\n}\n\n// Subsequent events (user identified)\n{\n  \"event_name\": \"product_purchased\",\n  \"anonymous_id\": \"anon_device_123\",\n  \"user_id\": \"usr_abc456\"\n}\n</code></pre>"},{"location":"lectures/Lecture01_Foundations/#145-from-events-to-features-the-data-science-connection","title":"1.4.5 From Events to Features: The Data Science Connection","text":"<p>For data scientists, events are the raw material for behavioral features:</p> <pre><code>import pandas as pd\n\n# Raw events\nevents = pd.DataFrame([\n    {\"user_id\": \"u1\", \"event\": \"page_view\", \"timestamp\": \"2025-01-01 10:00:00\", \n     \"properties\": {\"page\": \"home\"}},\n    {\"user_id\": \"u1\", \"event\": \"product_viewed\", \"timestamp\": \"2025-01-01 10:05:00\",\n     \"properties\": {\"product_id\": \"p1\", \"price\": 99.99}},\n    {\"user_id\": \"u1\", \"event\": \"add_to_cart\", \"timestamp\": \"2025-01-01 10:07:00\",\n     \"properties\": {\"product_id\": \"p1\"}},\n    {\"user_id\": \"u1\", \"event\": \"purchase\", \"timestamp\": \"2025-01-01 10:15:00\",\n     \"properties\": {\"order_total\": 99.99}},\n    {\"user_id\": \"u2\", \"event\": \"page_view\", \"timestamp\": \"2025-01-01 11:00:00\",\n     \"properties\": {\"page\": \"home\"}},\n    {\"user_id\": \"u2\", \"event\": \"page_view\", \"timestamp\": \"2025-01-01 11:30:00\",\n     \"properties\": {\"page\": \"pricing\"}},\n])\n\n# Transform to user-level features for ML\nuser_features = events.groupby('user_id').agg(\n    total_events=('event', 'count'),\n    unique_event_types=('event', 'nunique'),\n    session_duration_minutes=('timestamp', lambda x: \n        (pd.to_datetime(x).max() - pd.to_datetime(x).min()).seconds / 60),\n    viewed_products=('event', lambda x: (x == 'product_viewed').sum()),\n    made_purchase=('event', lambda x: 'purchase' in x.values),\n).reset_index()\n\nprint(user_features)\n</code></pre> <p>Output: <pre><code>  user_id  total_events  unique_event_types  session_duration_minutes  viewed_products  made_purchase\n0      u1             4                   4                      15.0                1           True\n1      u2             2                   1                      30.0                0          False\n</code></pre></p>"},{"location":"lectures/Lecture01_Foundations/#15-summary-and-key-concepts","title":"1.5 Summary and Key Concepts","text":"<p>This chapter established the foundational concepts necessary for understanding data engineering:</p>"},{"location":"lectures/Lecture01_Foundations/#the-data-lifecycle","title":"The Data Lifecycle","text":"<p>Data flows through eight stages: Generation \u2192 Collection \u2192 Storage \u2192 Transformation \u2192 Analysis \u2192 Serving \u2192 Maintenance \u2192 Archival. Understanding this complete journey enables you to trace data quality issues, design better systems, and collaborate effectively across roles.</p>"},{"location":"lectures/Lecture01_Foundations/#roles-in-the-data-ecosystem","title":"Roles in the Data Ecosystem","text":"<p>Multiple specialized roles contribute to the data lifecycle. As a data scientist, developing data engineering literacy makes you more effective and self-sufficient.</p>"},{"location":"lectures/Lecture01_Foundations/#events-as-foundational-data","title":"Events as Foundational Data","text":"<p>Modern behavioral data is captured through events\u2014discrete records of actions with timestamps, identities, and rich contextual properties. Well-designed event architectures enable powerful analytics and machine learning.</p>"},{"location":"lectures/Lecture01_Foundations/#16-further-reading-and-resources","title":"1.6 Further Reading and Resources","text":""},{"location":"lectures/Lecture01_Foundations/#books","title":"Books","text":"<ul> <li>Reis, J. &amp; Housley, M. (2022). Fundamentals of Data Engineering. O'Reilly Media. The definitive introduction to data engineering concepts and practices.</li> <li>Kleppmann, M. (2017). Designing Data-Intensive Applications. O'Reilly Media. Deep exploration of the principles underlying modern data systems.</li> </ul>"},{"location":"lectures/Lecture01_Foundations/#papers","title":"Papers","text":"<ul> <li>Zha, D. et al. (2023). \"Data-centric Artificial Intelligence: A Survey.\" arXiv:2303.10158. Comprehensive overview of data-centric approaches to AI. https://arxiv.org/abs/2303.10158</li> <li>Nazabal, A. et al. (2020). \"Data Engineering for Data Analytics: A Classification of the Issues, and Case Studies.\" arXiv:2004.12929. Classification of data engineering tasks with practical examples. https://arxiv.org/abs/2004.12929</li> </ul>"},{"location":"lectures/Lecture01_Foundations/#online-resources","title":"Online Resources","text":"<ul> <li>Data Engineering Handbook (GitHub): Comprehensive collection of resources, tools, and learning paths. https://github.com/DataExpert-io/data-engineer-handbook</li> <li>DataTalks.Club Data Engineering Zoomcamp: Free, project-based course covering modern data engineering tools and practices. https://github.com/DataTalksClub/data-engineering-zoomcamp</li> </ul>"},{"location":"lectures/Lecture01_Foundations/#17-exercises","title":"1.7 Exercises","text":"<p>Exercise 1.1: Data Lifecycle Mapping Choose a dataset you have worked with recently. Trace its journey through the data lifecycle: - Where was the data originally generated? - How was it collected and by whom? - Where is it stored? - What transformations were applied before you received it? - What limitations might exist due to decisions made at each stage?</p> <p>Exercise 1.2: Event Schema Design Design an event tracking schema for one of the following scenarios: - A music streaming application (like Spotify) - A food delivery service (like DoorDash) - An online learning platform (like Coursera)</p> <p>For each scenario: 1. Identify 10-15 key events to track 2. Define properties for each event 3. Document your naming conventions 4. Consider what context should be captured automatically</p> <p>Exercise 1.3: Event to Feature Transformation Given the following raw events, create five user-level features that could be useful for predicting user churn:</p> <pre><code>{\"user_id\": \"u1\", \"event\": \"app_opened\", \"timestamp\": \"2025-01-01T10:00:00Z\"}\n{\"user_id\": \"u1\", \"event\": \"content_viewed\", \"timestamp\": \"2025-01-01T10:05:00Z\", \"properties\": {\"content_type\": \"video\", \"duration_seconds\": 300}}\n{\"user_id\": \"u1\", \"event\": \"content_liked\", \"timestamp\": \"2025-01-01T10:10:00Z\"}\n{\"user_id\": \"u1\", \"event\": \"app_closed\", \"timestamp\": \"2025-01-01T10:30:00Z\"}\n{\"user_id\": \"u2\", \"event\": \"app_opened\", \"timestamp\": \"2025-01-01T11:00:00Z\"}\n{\"user_id\": \"u2\", \"event\": \"error_occurred\", \"timestamp\": \"2025-01-01T11:01:00Z\"}\n{\"user_id\": \"u2\", \"event\": \"app_closed\", \"timestamp\": \"2025-01-01T11:02:00Z\"}\n</code></pre>"},{"location":"lectures/Lecture01_Foundations/#chapter-2-data-types-and-file-formats-the-building-blocks","title":"Chapter 2: Data Types and File Formats \u2014 The Building Blocks","text":"<p>\"The goal is to turn data into information, and information into insight.\" \u2014 Carly Fiorina, former CEO of Hewlett-Packard</p>"},{"location":"lectures/Lecture01_Foundations/#21-introduction-why-format-matters","title":"2.1 Introduction: Why Format Matters","text":"<p>When you load a dataset into pandas with <code>pd.read_csv()</code>, a complex series of operations occurs behind the scenes. The file is read from disk, bytes are decoded into characters, delimiters are detected, columns are parsed, and data types are inferred. This seemingly simple operation embodies fundamental decisions about how data is represented, stored, and accessed.</p> <p>The choice of data format affects:</p> <ul> <li>Storage costs: Some formats are 10x more compact than others</li> <li>Query performance: The right format can make queries 100x faster</li> <li>Processing efficiency: Format determines how data flows through pipelines</li> <li>Interoperability: Different systems support different formats</li> <li>Schema evolution: Some formats handle changes gracefully; others break</li> </ul> <p>This chapter provides a comprehensive understanding of data types and file formats\u2014knowledge that will inform every data engineering decision you make.</p>"},{"location":"lectures/Lecture01_Foundations/#22-the-data-structure-spectrum","title":"2.2 The Data Structure Spectrum","text":"<p>Not all data fits neatly into spreadsheet rows and columns. Understanding the spectrum of data structures helps you choose appropriate storage and processing strategies.</p>"},{"location":"lectures/Lecture01_Foundations/#221-structured-data","title":"2.2.1 Structured Data","text":"<p>Structured data conforms to a fixed schema with predefined columns and data types. Every record has the same fields in the same order.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 customer_id\u2502 name            \u2502 age     \u2502 email      \u2502 signup_dt \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 1          \u2502 Alice Smith     \u2502 28      \u2502 alice@...  \u2502 2024-01-15\u2502\n\u2502 2          \u2502 Bob Johnson     \u2502 35      \u2502 bob@...    \u2502 2024-02-20\u2502\n\u2502 3          \u2502 Carol Williams  \u2502 42      \u2502 carol@...  \u2502 2024-03-10\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Characteristics: - Schema defined before data insertion (schema-on-write) - Fixed columns with enforced data types - Naturally maps to relational database tables - Easily queried with SQL - Efficient storage due to predictable structure</p> <p>Common sources: Relational databases, ERP systems, financial records, CRM data</p>"},{"location":"lectures/Lecture01_Foundations/#222-semi-structured-data","title":"2.2.2 Semi-Structured Data","text":"<p>Semi-structured data has some organizational properties but does not conform to a rigid schema. It is self-describing, with tags or keys that identify data elements.</p> <pre><code>{\n  \"customer_id\": 1,\n  \"name\": \"Alice Smith\",\n  \"age\": 28,\n  \"contacts\": {\n    \"email\": \"alice@example.com\",\n    \"phone\": \"+1-555-0123\",\n    \"preferences\": {\n      \"newsletter\": true,\n      \"sms\": false\n    }\n  },\n  \"orders\": [\n    {\"order_id\": \"o1\", \"total\": 150.00, \"items\": 3},\n    {\"order_id\": \"o2\", \"total\": 89.99, \"items\": 1}\n  ],\n  \"tags\": [\"premium\", \"early_adopter\"]\n}\n</code></pre> <p>Characteristics: - Flexible schema (fields can vary between records) - Supports nested structures (objects within objects) - Self-describing (keys explain the data) - Schema can evolve without breaking existing data - Requires more sophisticated querying</p> <p>Common sources: JSON APIs, event tracking data, log files, NoSQL databases, configuration files</p>"},{"location":"lectures/Lecture01_Foundations/#223-unstructured-data","title":"2.2.3 Unstructured Data","text":"<p>Unstructured data lacks any predefined organizational structure. It must be processed or analyzed to extract meaningful information.</p> <p>Examples: - Text: Emails, documents, social media posts, customer reviews - Images: Photographs, scanned documents, medical imaging - Audio: Call recordings, podcasts, voice messages - Video: Surveillance footage, user-generated content, training videos</p> <p>Characteristics: - No inherent schema - Requires specialized processing (NLP, computer vision, etc.) - Often the largest volume of organizational data - High potential value, but difficult to extract</p> <p>Processing unstructured data:</p> <pre><code># Text analysis example\nraw_text = \"I absolutely love this product! Fast shipping and great quality.\"\n\n# After NLP processing, we extract structured information:\nprocessed = {\n    \"sentiment\": \"positive\",\n    \"sentiment_score\": 0.92,\n    \"topics\": [\"product_quality\", \"shipping\"],\n    \"entities\": [],\n    \"language\": \"en\"\n}\n</code></pre>"},{"location":"lectures/Lecture01_Foundations/#224-the-queryability-spectrum","title":"2.2.4 The Queryability Spectrum","text":"<pre><code>STRUCTURED                SEMI-STRUCTURED              UNSTRUCTURED\n    \u2502                           \u2502                            \u2502\n    \u2502  SELECT * FROM users      \u2502  $.orders[*].total         \u2502  [Requires ML/AI]\n    \u2502  WHERE age &gt; 25           \u2502  WHERE name = 'Alice'      \u2502  \n    \u2502                           \u2502                            \u2502\n    \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\n    Easy to Query                                    Difficult to Query\n    Rigid Schema                                     No Schema\n    Small Storage                                    Large Storage\n</code></pre>"},{"location":"lectures/Lecture01_Foundations/#23-file-formats-a-comprehensive-guide","title":"2.3 File Formats: A Comprehensive Guide","text":"<p>The choice of file format is one of the most consequential decisions in data engineering. This section provides deep coverage of the formats you will encounter.</p>"},{"location":"lectures/Lecture01_Foundations/#231-text-based-formats","title":"2.3.1 Text-Based Formats","text":""},{"location":"lectures/Lecture01_Foundations/#csv-comma-separated-values","title":"CSV (Comma-Separated Values)","text":"<p>CSV is the oldest and most universal data exchange format. Its simplicity is both its greatest strength and its most significant limitation.</p> <p>Structure: <pre><code>customer_id,name,age,signup_date,is_active\n1,Alice Smith,28,2024-01-15,true\n2,\"Johnson, Bob\",35,2024-02-20,true\n3,Carol Williams,42,2024-03-10,false\n</code></pre></p> <p>Technical Details: - Encoding: Typically UTF-8, but varies (beware of Excel's default encoding) - Delimiter: Comma by default, but tab (<code>\\t</code>) and pipe (<code>|</code>) are common alternatives - Quoting: Fields containing delimiters or newlines must be quoted - Headers: First row typically contains column names (but not guaranteed) - Types: All values stored as strings; types must be inferred or specified</p> <p>Advantages: - Universal compatibility (every tool can read CSV) - Human readable and editable - Simple to generate and parse - No dependencies or special libraries required</p> <p>Disadvantages:</p> <p>As noted in technical discussions: \"CSV is just a string, meaning the dataset is larger by storing all characters according to the file-encoding; there is no type-information or schema associated with the data, and it will always be parsed while deserialized\" (Stack Overflow, 2022).</p> <p>Additional limitations: - No standard specification (many dialects exist) - No support for nested or hierarchical data - Poor compression (text is verbose) - Ambiguous handling of null values - Date/time formats vary wildly - Encoding issues are common</p> <p>When to use: - Small datasets (under 100MB) - Data exchange with non-technical stakeholders - Legacy system integration - Quick prototyping and exploration</p> <p>Python usage: <pre><code>import pandas as pd\n\n# Reading with explicit options for reliability\ndf = pd.read_csv(\n    'data.csv',\n    encoding='utf-8',\n    dtype={'customer_id': 'int32', 'name': 'string'},\n    parse_dates=['signup_date'],\n    na_values=['', 'NULL', 'N/A']\n)\n\n# Writing with consistent formatting\ndf.to_csv('output.csv', index=False, date_format='%Y-%m-%d')\n</code></pre></p>"},{"location":"lectures/Lecture01_Foundations/#json-javascript-object-notation","title":"JSON (JavaScript Object Notation)","text":"<p>JSON emerged from JavaScript but has become the lingua franca of web APIs and configuration files. Its ability to represent nested structures makes it far more expressive than CSV.</p> <p>Structure: <pre><code>{\n  \"customers\": [\n    {\n      \"customer_id\": 1,\n      \"name\": \"Alice Smith\",\n      \"age\": 28,\n      \"contacts\": {\n        \"email\": \"alice@example.com\",\n        \"phone\": \"+1-555-0123\"\n      },\n      \"orders\": [\n        {\"order_id\": \"o1\", \"total\": 150.00},\n        {\"order_id\": \"o2\", \"total\": 89.99}\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"extracted_at\": \"2025-11-29T10:30:00Z\",\n    \"record_count\": 1\n  }\n}\n</code></pre></p> <p>Technical Details: - Data types: strings, numbers, booleans, null, arrays, objects - Encoding: Must be UTF-8 (per RFC 8259) - No comments: JSON does not support comments (though some parsers allow them) - Strict syntax: Trailing commas and single quotes are invalid</p> <p>Variants: - JSON Lines (JSONL/NDJSON): One JSON object per line, enabling streaming - GeoJSON: JSON format for geographic data - JSON Schema: Specification for validating JSON structure</p> <p>Advantages: - Human readable (more so than CSV for complex data) - Native support for nested structures - Self-describing (keys provide context) - Universal support in programming languages - Natural fit for API responses</p> <p>Disadvantages: - Verbose (keys repeated for every record) - No native date/time type (dates are strings) - Slow for large-scale analytics - Memory-intensive for large files (must often parse entirely)</p> <p>When to use: - API responses and requests - Configuration files - Document storage - Data interchange between systems - Event data (before analytical processing)</p> <p>Python usage: <pre><code>import json\nimport pandas as pd\nfrom pandas import json_normalize\n\n# Reading JSON\nwith open('data.json', 'r') as f:\n    data = json.load(f)\n\n# Flattening nested JSON to DataFrame\ndf = json_normalize(\n    data['customers'],\n    record_path='orders',\n    meta=['customer_id', 'name', ['contacts', 'email']],\n    meta_prefix='customer_'\n)\n\n# Reading JSON Lines (streaming-friendly)\ndf = pd.read_json('data.jsonl', lines=True)\n\n# Writing JSON\ndf.to_json('output.json', orient='records', indent=2, date_format='iso')\n</code></pre></p>"},{"location":"lectures/Lecture01_Foundations/#232-binary-columnar-formats","title":"2.3.2 Binary Columnar Formats","text":"<p>Binary columnar formats represent a paradigm shift from row-based storage. They are essential for modern analytics and big data processing.</p>"},{"location":"lectures/Lecture01_Foundations/#understanding-columnar-storage","title":"Understanding Columnar Storage","text":"<p>The fundamental insight of columnar storage is that analytical queries typically access many rows but few columns:</p> <pre><code>-- This query touches only 2 columns out of potentially dozens\nSELECT AVG(price), COUNT(*) \nFROM transactions \nWHERE transaction_date &gt;= '2025-01-01'\n</code></pre> <p>Row-based storage (CSV, Avro): <pre><code>Row 1: [id=1, name=\"Alice\", age=28, city=\"NYC\", salary=75000, ...]\nRow 2: [id=2, name=\"Bob\", age=35, city=\"LA\", salary=82000, ...]\nRow 3: [id=3, name=\"Carol\", age=42, city=\"Chicago\", salary=91000, ...]\n\nTo read 'age' column: Must scan through entire rows\n</code></pre></p> <p>Column-based storage (Parquet, ORC): <pre><code>id column:     [1, 2, 3, 4, 5, ...]\nname column:   [\"Alice\", \"Bob\", \"Carol\", ...]\nage column:    [28, 35, 42, ...]    \u2190 Read only this!\ncity column:   [\"NYC\", \"LA\", \"Chicago\", ...]\nsalary column: [75000, 82000, 91000, ...]\n\nTo read 'age' column: Read only the age column block\n</code></pre></p> <p>Benefits of columnar storage: 1. Column pruning: Read only the columns needed for a query 2. Better compression: Similar values in a column compress well together 3. Vectorized processing: CPUs can process columns more efficiently 4. Predicate pushdown: Skip entire row groups based on column statistics</p>"},{"location":"lectures/Lecture01_Foundations/#parquet","title":"Parquet","text":"<p>Apache Parquet is the dominant columnar format for analytics and the default format for Apache Spark. Understanding Parquet is essential for any data practitioner.</p> <p>File Structure:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           PARQUET FILE                                   \u2502\n\u2502                                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502                        ROW GROUP 1                                 \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502  \u2502\n\u2502  \u2502  \u2502 Column Chunk\u2502  \u2502 Column Chunk\u2502  \u2502 Column Chunk\u2502                \u2502  \u2502\n\u2502  \u2502  \u2502   (id)      \u2502  \u2502   (name)    \u2502  \u2502   (age)     \u2502                \u2502  \u2502\n\u2502  \u2502  \u2502             \u2502  \u2502             \u2502  \u2502             \u2502                \u2502  \u2502\n\u2502  \u2502  \u2502 \u2022 Data Pages\u2502  \u2502 \u2022 Data Pages\u2502  \u2502 \u2022 Data Pages\u2502                \u2502  \u2502\n\u2502  \u2502  \u2502 \u2022 Dict Page \u2502  \u2502 \u2022 Dict Page \u2502  \u2502 \u2022 Statistics\u2502                \u2502  \u2502\n\u2502  \u2502  \u2502 \u2022 Statistics\u2502  \u2502 \u2022 Statistics\u2502  \u2502   (min/max) \u2502                \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502                        ROW GROUP 2                                 \u2502  \u2502\n\u2502  \u2502  (same structure as Row Group 1)                                   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502                          FOOTER                                    \u2502  \u2502\n\u2502  \u2502  \u2022 File metadata                                                   \u2502  \u2502\n\u2502  \u2502  \u2022 Schema definition                                               \u2502  \u2502\n\u2502  \u2502  \u2022 Row group metadata                                              \u2502  \u2502\n\u2502  \u2502  \u2022 Column chunk locations                                          \u2502  \u2502\n\u2502  \u2502  \u2022 Key-value metadata (custom)                                     \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key Concepts:</p> <ul> <li>Row Groups: Horizontal partitions of the data (typically 128MB-1GB each)</li> <li>Column Chunks: A column's data within a row group</li> <li>Pages: The smallest unit of storage within a column chunk (typically 1MB)</li> <li>Footer: Metadata including schema, statistics, and locations</li> </ul> <p>Schema Embedded in File:</p> <p>\"Parquet stores the file schema in the file metadata. CSV files don't store file metadata, so readers need to either be supplied with the schema or the schema needs to be inferred\" (MrPowers, Stack Overflow).</p> <p>Compression and Encoding:</p> <p>Parquet supports multiple compression codecs: - Snappy: Fast compression/decompression, moderate ratio (default) - Gzip: Higher compression ratio, slower - LZ4: Very fast, lower ratio - Zstd: Good balance of speed and ratio</p> <p>Parquet also uses encoding schemes optimized for each data type: - Dictionary encoding: For columns with repeated values - Run-length encoding (RLE): For sequences of repeated values - Delta encoding: For sorted or incrementing values</p> <p>Predicate Pushdown:</p> <p>Parquet's column statistics enable query engines to skip irrelevant data:</p> <pre><code># Query: SELECT * FROM sales WHERE sale_date = '2025-11-29'\n\n# Row Group 1 statistics: sale_date min='2025-01-01', max='2025-06-30'\n#   \u2192 SKIP (date not in range)\n\n# Row Group 2 statistics: sale_date min='2025-07-01', max='2025-12-31'\n#   \u2192 READ (date might be in range)\n</code></pre> <p>When to use Parquet: - Analytical queries and data warehousing - Data lake storage - Spark, Presto, Athena, BigQuery workloads - Any dataset over 100MB used for analysis - Long-term data archival</p> <p>\"Parquet is a default data file format for Spark\" (Towards Data Science, 2023).</p> <p>Python usage: <pre><code>import pandas as pd\nimport pyarrow.parquet as pq\n\n# Reading Parquet\ndf = pd.read_parquet('data.parquet')\n\n# Reading specific columns only (column pruning)\ndf = pd.read_parquet('data.parquet', columns=['customer_id', 'age', 'revenue'])\n\n# Writing Parquet with options\ndf.to_parquet(\n    'output.parquet',\n    engine='pyarrow',\n    compression='snappy',\n    index=False\n)\n\n# Advanced: Reading with filters (predicate pushdown)\ndf = pd.read_parquet(\n    'data.parquet',\n    filters=[('year', '=', 2025), ('country', 'in', ['US', 'UK'])]\n)\n\n# PySpark usage\nspark_df = spark.read.parquet('s3://bucket/data/')\nspark_df.write.parquet('s3://bucket/output/', mode='overwrite')\n</code></pre></p>"},{"location":"lectures/Lecture01_Foundations/#avro","title":"Avro","text":"<p>Apache Avro is a row-based binary format designed for data serialization, particularly in streaming contexts.</p> <p>Structure:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            AVRO FILE                                     \u2502\n\u2502                                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502                           HEADER                                   \u2502  \u2502\n\u2502  \u2502  \u2022 Magic bytes (Obj1)                                              \u2502  \u2502\n\u2502  \u2502  \u2022 Schema (JSON)                                                   \u2502  \u2502\n\u2502  \u2502  \u2022 Sync marker (16 bytes)                                          \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502                        DATA BLOCK 1                                \u2502  \u2502\n\u2502  \u2502  \u2022 Object count                                                    \u2502  \u2502\n\u2502  \u2502  \u2022 Serialized objects (compressed)                                 \u2502  \u2502\n\u2502  \u2502  \u2022 Sync marker                                                     \u2502  \u2502\n\u2502  \u2502                                                                    \u2502  \u2502\n\u2502  \u2502  Row 1: [1, \"Alice\", 28, \"2024-01-15\"]                            \u2502  \u2502\n\u2502  \u2502  Row 2: [2, \"Bob\", 35, \"2024-02-20\"]                               \u2502  \u2502\n\u2502  \u2502  ...                                                               \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502                        DATA BLOCK 2                                \u2502  \u2502\n\u2502  \u2502  (same structure)                                                  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Schema Definition:</p> <p>Avro schemas are defined in JSON:</p> <pre><code>{\n  \"type\": \"record\",\n  \"name\": \"Customer\",\n  \"namespace\": \"com.example\",\n  \"fields\": [\n    {\"name\": \"customer_id\", \"type\": \"int\"},\n    {\"name\": \"name\", \"type\": \"string\"},\n    {\"name\": \"age\", \"type\": [\"null\", \"int\"], \"default\": null},\n    {\"name\": \"signup_date\", \"type\": {\n      \"type\": \"int\",\n      \"logicalType\": \"date\"\n    }},\n    {\"name\": \"tags\", \"type\": {\"type\": \"array\", \"items\": \"string\"}}\n  ]\n}\n</code></pre> <p>Schema Evolution:</p> <p>Avro's killer feature is robust schema evolution. You can: - Add fields (with defaults) without breaking readers - Remove fields without breaking readers (if they have defaults) - Rename fields using aliases</p> <p>This makes Avro ideal for streaming systems where producers and consumers may be updated independently.</p> <p>Compression:</p> <p>\"Avro uses a binary format which benefits data compaction. Binary data is highly compact compared to JSON or XML formats. Hence the speed of serialization and deserialization also increases\" (Hevo Data, 2024).</p> <p>When to use Avro: - Apache Kafka message serialization - Real-time streaming pipelines - Systems requiring schema evolution - Write-heavy workloads - Data interchange between services</p> <p>Python usage: <pre><code>from fastavro import writer, reader, parse_schema\n\n# Define schema\nschema = {\n    \"type\": \"record\",\n    \"name\": \"Customer\",\n    \"fields\": [\n        {\"name\": \"customer_id\", \"type\": \"int\"},\n        {\"name\": \"name\", \"type\": \"string\"},\n        {\"name\": \"age\", \"type\": \"int\"}\n    ]\n}\nparsed_schema = parse_schema(schema)\n\n# Write Avro\nrecords = [\n    {\"customer_id\": 1, \"name\": \"Alice\", \"age\": 28},\n    {\"customer_id\": 2, \"name\": \"Bob\", \"age\": 35}\n]\n\nwith open('customers.avro', 'wb') as f:\n    writer(f, parsed_schema, records)\n\n# Read Avro\nwith open('customers.avro', 'rb') as f:\n    for record in reader(f):\n        print(record)\n</code></pre></p>"},{"location":"lectures/Lecture01_Foundations/#233-format-comparison","title":"2.3.3 Format Comparison","text":"<p>Storage Efficiency:</p> <p>Testing with identical data reveals dramatic differences:</p> <p>\"Both CSV and JSON are losing a lot compared to Avro and Parquet, however, this is expected because both Avro and Parquet are binary formats (they also use compression) while CSV and JSON are not compressed\" (DataCrump, 2023).</p> Format Relative Size Notes JSON 140% Keys repeated, no compression CSV 100% Baseline (uncompressed) CSV (gzip) 15-25% Compressed text Avro 25-40% Binary, row-based Parquet 10-20% Binary, columnar, excellent compression <p>Query Performance:</p> <p>For analytical queries selecting specific columns:</p> Format Relative Query Time CSV 100% (baseline) JSON 120-150% Avro 50-70% Parquet 5-15% <p>The dramatic improvement with Parquet comes from column pruning and predicate pushdown.</p> <p>Decision Framework:</p> <p>\"CSV and JSON are suitable for small datasets (&lt;1,000,000 rows) or quick implementations, while Parquet, Avro, or ORC are better for large datasets with specific data behaviors\" (Medium, 2024).</p> <pre><code>                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502         FORMAT SELECTION GUIDE          \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                       \u2502\n                                       \u25bc\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502        Is the data &gt; 100MB?             \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                       \u2502\n                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                      \u2502 NO                              \u2502 YES\n                      \u25bc                                 \u25bc\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 Need human editing?  \u2502          \u2502 Streaming/real-time? \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502                              \u2502\n           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n           \u2502 YES            NO   \u2502        \u2502 YES           NO  \u2502\n           \u25bc                \u25bc    \u2502        \u25bc               \u25bc   \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n        \u2502 CSV  \u2502        \u2502 JSON \u2502\u2502     \u2502 AVRO \u2502       \u2502PARQUET\u2502\n        \u2502      \u2502        \u2502      \u2502\u2502     \u2502      \u2502       \u2502      \u2502\u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n                                \u2502                            \u2502\n                                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"lectures/Lecture01_Foundations/#24-data-types-precision-and-efficiency","title":"2.4 Data Types: Precision and Efficiency","text":"<p>Within any format, data is represented using specific types. Understanding types improves both correctness and performance.</p>"},{"location":"lectures/Lecture01_Foundations/#241-numeric-types","title":"2.4.1 Numeric Types","text":"Type Size Range Use Case <code>int8</code> / <code>tinyint</code> 1 byte -128 to 127 Age, small counts <code>int16</code> / <code>smallint</code> 2 bytes -32,768 to 32,767 Year, medium counts <code>int32</code> / <code>int</code> 4 bytes \u00b12.1 billion Most integers <code>int64</code> / <code>bigint</code> 8 bytes \u00b19.2 quintillion Large IDs, timestamps <code>float32</code> / <code>float</code> 4 bytes ~7 decimal digits Approximate values <code>float64</code> / <code>double</code> 8 bytes ~15 decimal digits Scientific, financial <code>decimal</code> Variable Exact precision Currency, percentages <p>Choosing the right numeric type:</p> <pre><code>import pandas as pd\nimport numpy as np\n\n# Memory comparison\nn = 1_000_000\n\n# Using default int64 (8 bytes \u00d7 1M = 8MB)\nages_int64 = pd.Series(np.random.randint(0, 100, n), dtype='int64')\nprint(f\"int64: {ages_int64.memory_usage() / 1e6:.1f} MB\")  # 8.0 MB\n\n# Using int8 (1 byte \u00d7 1M = 1MB) - ages fit in 0-127\nages_int8 = ages_int64.astype('int8')\nprint(f\"int8: {ages_int8.memory_usage() / 1e6:.1f} MB\")    # 1.0 MB\n\n# 8x memory savings!\n</code></pre>"},{"location":"lectures/Lecture01_Foundations/#242-string-types","title":"2.4.2 String Types","text":"<p>Strings are often the largest memory consumers in datasets:</p> <pre><code># String optimization with categories\ndf = pd.DataFrame({\n    'country': np.random.choice(['USA', 'UK', 'Germany', 'France'], 1_000_000)\n})\n\n# Default object dtype\nprint(f\"Object: {df['country'].memory_usage(deep=True) / 1e6:.1f} MB\")  # ~64 MB\n\n# Category dtype (for low-cardinality strings)\ndf['country'] = df['country'].astype('category')\nprint(f\"Category: {df['country'].memory_usage(deep=True) / 1e6:.1f} MB\")  # ~1 MB\n</code></pre>"},{"location":"lectures/Lecture01_Foundations/#243-date-and-time-types","title":"2.4.3 Date and Time Types","text":"<p>Temporal data requires careful handling:</p> Type Storage Precision Example <code>date</code> 4 bytes Day 2025-11-29 <code>datetime64[ns]</code> 8 bytes Nanosecond 2025-11-29 14:30:15.123456789 <code>timestamp</code> 8 bytes Varies Unix epoch milliseconds <code>time</code> Variable Sub-second 14:30:15.123 <code>interval</code> Variable Duration 3 days, 4 hours <p>Best practices: - Store timestamps in UTC - Use ISO 8601 format for string representation - Be explicit about timezone handling - Choose appropriate precision (do you need nanoseconds?)</p> <pre><code>import pandas as pd\n\n# Parse dates explicitly\ndf = pd.read_csv('data.csv', parse_dates=['created_at', 'updated_at'])\n\n# Handle timezones\ndf['created_at'] = pd.to_datetime(df['created_at'], utc=True)\ndf['created_at_local'] = df['created_at'].dt.tz_convert('America/New_York')\n</code></pre>"},{"location":"lectures/Lecture01_Foundations/#244-boolean-and-null-types","title":"2.4.4 Boolean and Null Types","text":"<ul> <li>Boolean: <code>true</code>/<code>false</code> - ideally 1 bit, often stored as 1 byte</li> <li>Null/None: Represents missing data - handling varies by system</li> </ul> <p>Null handling strategies:</p> Strategy When to Use Keep as null Value is genuinely unknown Default value Reasonable default exists (0 for counts) Sentinel value -1, \"UNKNOWN\", empty string Imputation Statistical estimate appropriate Exclusion Analysis can proceed without the record"},{"location":"lectures/Lecture01_Foundations/#25-working-with-nested-data","title":"2.5 Working with Nested Data","text":"<p>Semi-structured data with nested objects and arrays requires special handling to prepare for analysis.</p>"},{"location":"lectures/Lecture01_Foundations/#251-the-nested-data-challenge","title":"2.5.1 The Nested Data Challenge","text":"<p>Consider this common e-commerce data structure:</p> <pre><code>{\n  \"order_id\": \"ord_12345\",\n  \"customer\": {\n    \"id\": \"cust_789\",\n    \"name\": \"Alice Smith\",\n    \"address\": {\n      \"street\": \"123 Main St\",\n      \"city\": \"San Francisco\",\n      \"state\": \"CA\",\n      \"zip\": \"94102\"\n    }\n  },\n  \"items\": [\n    {\n      \"product_id\": \"prod_001\",\n      \"name\": \"Wireless Headphones\",\n      \"price\": 249.99,\n      \"quantity\": 1\n    },\n    {\n      \"product_id\": \"prod_002\",\n      \"name\": \"Phone Case\",\n      \"price\": 29.99,\n      \"quantity\": 2\n    }\n  ],\n  \"totals\": {\n    \"subtotal\": 309.97,\n    \"tax\": 27.90,\n    \"shipping\": 0,\n    \"total\": 337.87\n  }\n}\n</code></pre> <p>This cannot be directly loaded into a flat table. We need flattening strategies.</p>"},{"location":"lectures/Lecture01_Foundations/#252-flattening-strategies","title":"2.5.2 Flattening Strategies","text":"<p>Strategy 1: Dot notation flattening (nested objects)</p> <pre><code>from pandas import json_normalize\n\ndata = {...}  # The JSON above\n\n# Flatten nested objects\ndf = json_normalize(data)\n\n# Result:\n# order_id | customer.id | customer.name | customer.address.street | ... | items | totals.total\n# ord_12345| cust_789    | Alice Smith   | 123 Main St             | ... | [...]  | 337.87\n</code></pre> <p>Strategy 2: Exploding arrays</p> <pre><code># Explode the items array\ndf = json_normalize(\n    data,\n    record_path='items',                    # Array to explode\n    meta=['order_id',                       # Fields to keep from parent\n          ['customer', 'id'],\n          ['customer', 'name'],\n          ['totals', 'total']],\n    meta_prefix='order_'                    # Prefix for parent fields\n)\n\n# Result:\n# product_id | name               | price  | quantity | order_order_id | order_customer.id | order_totals.total\n# prod_001   | Wireless Headphones| 249.99 | 1        | ord_12345      | cust_789          | 337.87\n# prod_002   | Phone Case         | 29.99  | 2        | ord_12345      | cust_789          | 337.87\n</code></pre> <p>Strategy 3: PySpark approach</p> <pre><code>from pyspark.sql import functions as F\n\n# Read nested JSON\ndf = spark.read.json(\"orders.json\")\n\n# Access nested fields with dot notation\ndf.select(\n    \"order_id\",\n    \"customer.id\",\n    \"customer.name\",\n    \"customer.address.city\"\n)\n\n# Explode arrays\ndf_items = df.select(\n    \"order_id\",\n    \"customer.id\",\n    F.explode(\"items\").alias(\"item\")\n).select(\n    \"order_id\",\n    \"id\",\n    \"item.product_id\",\n    \"item.name\",\n    \"item.price\",\n    \"item.quantity\"\n)\n</code></pre>"},{"location":"lectures/Lecture01_Foundations/#253-when-to-flatten-vs-keep-nested","title":"2.5.3 When to Flatten vs. Keep Nested","text":"Keep Nested Flatten Document databases (MongoDB) Analytical queries API responses Machine learning features Event archives Reporting and BI Schema flexibility needed SQL-based analysis"},{"location":"lectures/Lecture01_Foundations/#26-summary-and-key-concepts","title":"2.6 Summary and Key Concepts","text":"<p>This chapter provided comprehensive coverage of data types and file formats:</p>"},{"location":"lectures/Lecture01_Foundations/#data-structure-spectrum","title":"Data Structure Spectrum","text":"<ul> <li>Structured: Fixed schema, tables, SQL-queryable</li> <li>Semi-structured: Flexible, nested, self-describing (JSON, XML)</li> <li>Unstructured: No schema, requires ML/NLP to process</li> </ul>"},{"location":"lectures/Lecture01_Foundations/#file-format-selection","title":"File Format Selection","text":"<ul> <li>CSV: Universal but limited\u2014use for small data and interchange</li> <li>JSON: Flexible, nested support\u2014use for APIs and configuration</li> <li>Parquet: Columnar, compressed\u2014use for analytics and data lakes</li> <li>Avro: Row-based, schema evolution\u2014use for streaming and Kafka</li> </ul>"},{"location":"lectures/Lecture01_Foundations/#key-insight","title":"Key Insight","text":"<p>\"JSON has the largest footprint because it stores the schema attributes for each row. For this reason, I rarely store JSON or CSV formats in curated and transformed zone in a data lake\" (Towards Data Science, 2023).</p>"},{"location":"lectures/Lecture01_Foundations/#27-further-reading-and-resources","title":"2.7 Further Reading and Resources","text":""},{"location":"lectures/Lecture01_Foundations/#papers-and-articles","title":"Papers and Articles","text":"<ul> <li>Mbata, A. et al. (2024). \"A Survey of Pipeline Tools for Data Engineering.\" arXiv:2406.08335. Comprehensive survey of data engineering tools and formats. https://arxiv.org/abs/2406.08335</li> <li>Wickham, H. (2014). \"Tidy Data.\" Journal of Statistical Software. Foundational paper on data organization principles. https://vita.had.co.nz/papers/tidy-data.pdf</li> </ul>"},{"location":"lectures/Lecture01_Foundations/#technical-documentation","title":"Technical Documentation","text":"<ul> <li>Apache Parquet Documentation: https://parquet.apache.org/docs/</li> <li>Apache Avro Specification: https://avro.apache.org/docs/current/spec.html</li> <li>JSON Specification (RFC 8259): https://datatracker.ietf.org/doc/html/rfc8259</li> </ul>"},{"location":"lectures/Lecture01_Foundations/#practical-comparisons","title":"Practical Comparisons","text":"<ul> <li>DataCrump: CSV vs Parquet vs JSON vs Avro: Hands-on performance comparison with benchmarks. https://datacrump.com/csv-parquet-json-avro/</li> </ul>"},{"location":"lectures/Lecture01_Foundations/#books_1","title":"Books","text":"<ul> <li>Reis, J. &amp; Housley, M. (2022). Fundamentals of Data Engineering. O'Reilly Media. Chapter 5 covers data formats in depth.</li> <li>Kleppmann, M. (2017). Designing Data-Intensive Applications. O'Reilly Media. Chapter 4 discusses encoding and evolution.</li> </ul>"},{"location":"lectures/Lecture01_Foundations/#28-exercises","title":"2.8 Exercises","text":"<p>Exercise 2.1: Format Conversion and Comparison</p> <p>Take a CSV file of at least 100,000 rows and: 1. Convert it to JSON, Parquet, and Avro formats 2. Compare file sizes for each format 3. Measure read times for loading into pandas 4. Apply compression (gzip for CSV/JSON, snappy for Parquet) and compare again</p> <pre><code>import pandas as pd\nimport time\nimport os\n\n# Your code here\ndf = pd.read_csv('your_data.csv')\n\n# Save in different formats and measure\nformats = {\n    'csv': lambda: df.to_csv('output.csv', index=False),\n    'json': lambda: df.to_json('output.json', orient='records'),\n    'parquet': lambda: df.to_parquet('output.parquet'),\n}\n\nfor name, save_func in formats.items():\n    start = time.time()\n    save_func()\n    elapsed = time.time() - start\n    size = os.path.getsize(f'output.{name}') / 1e6\n    print(f\"{name}: {size:.2f} MB, {elapsed:.2f} seconds\")\n</code></pre> <p>Exercise 2.2: Nested Data Transformation</p> <p>Given this nested JSON structure, create a flat DataFrame suitable for analysis:</p> <pre><code>{\n  \"users\": [\n    {\n      \"id\": 1,\n      \"name\": \"Alice\",\n      \"profile\": {\n        \"age\": 28,\n        \"occupation\": \"Engineer\"\n      },\n      \"sessions\": [\n        {\"date\": \"2025-01-01\", \"duration_minutes\": 45, \"pages_viewed\": 12},\n        {\"date\": \"2025-01-02\", \"duration_minutes\": 30, \"pages_viewed\": 8}\n      ]\n    },\n    {\n      \"id\": 2,\n      \"name\": \"Bob\",\n      \"profile\": {\n        \"age\": 35,\n        \"occupation\": \"Designer\"\n      },\n      \"sessions\": [\n        {\"date\": \"2025-01-01\", \"duration_minutes\": 60, \"pages_viewed\": 20}\n      ]\n    }\n  ]\n}\n</code></pre> <p>Create two DataFrames: 1. User-level DataFrame with profile information 2. Session-level DataFrame with user context</p> <p>Exercise 2.3: Schema Design</p> <p>Design a data schema for a ride-sharing application (like Uber/Lyft). Consider: - What events should be tracked? - What fields should each event have? - What data types are appropriate for each field? - How should nested data (e.g., route waypoints) be structured?</p> <p>Document your schema in JSON Schema format.</p> <p>Exercise 2.4: Type Optimization</p> <p>Given a DataFrame with default types, optimize memory usage by selecting appropriate types:</p> <pre><code>import pandas as pd\nimport numpy as np\n\n# Create sample data with suboptimal types\ndf = pd.DataFrame({\n    'user_id': np.random.randint(1, 1000000, 1000000),        # Could be int32\n    'age': np.random.randint(18, 80, 1000000),                # Could be int8\n    'country': np.random.choice(['US', 'UK', 'DE', 'FR'], 1000000),  # Could be category\n    'is_premium': np.random.choice([True, False], 1000000),   # Already boolean\n    'balance': np.random.uniform(0, 10000, 1000000),          # Could be float32\n})\n\nprint(f\"Original memory: {df.memory_usage(deep=True).sum() / 1e6:.2f} MB\")\n\n# Your optimization code here\n# Target: Reduce memory by at least 50%\n</code></pre>"},{"location":"lectures/Lecture01_Foundations/#end-of-part-i-foundations","title":"End of Part I: Foundations","text":"<p>The next part of this course will cover Data Collection and Storage, including: - Chapter 3: Data Sources and Collection Methods - Chapter 4: Relational Databases and SQL - Chapter 5: Data Warehouses, Data Lakes, and Modern Storage Architectures</p>"},{"location":"lectures/Lecture2_Relational_Databases/","title":"Complete SQL Reference Guide","text":""},{"location":"lectures/Lecture2_Relational_Databases/#from-fundamentals-to-advanced-analytics","title":"From Fundamentals to Advanced Analytics","text":""},{"location":"lectures/Lecture2_Relational_Databases/#part-1-relational-database-fundamentals","title":"Part 1: Relational Database Fundamentals","text":""},{"location":"lectures/Lecture2_Relational_Databases/#11-what-is-a-relational-database","title":"1.1 What is a Relational Database?","text":"<p>A relational database is a type of database that organizes data into tables (also called relations) consisting of rows and columns. The \"relational\" part refers to how tables can be linked to each other through shared columns, enabling complex data relationships while minimizing redundancy.</p>"},{"location":"lectures/Lecture2_Relational_Databases/#core-terminology","title":"Core Terminology","text":"Term Definition Analogy Table (Relation) A collection of related data organized in rows and columns A spreadsheet tab Row (Record/Tuple) A single entry in a table representing one entity One line in a spreadsheet Column (Field/Attribute) A specific piece of data that each row contains A spreadsheet column header Schema The structure/blueprint of a database (tables, columns, relationships) The architectural plan Database A collection of related tables and other objects The entire filing cabinet"},{"location":"lectures/Lecture2_Relational_Databases/#why-relational-databases","title":"Why Relational Databases?","text":"<p>Relational databases solve fundamental data management problems:</p> <ol> <li>Data Integrity: Rules ensure data remains accurate and consistent</li> <li>Reduced Redundancy: Information stored once, referenced many times</li> <li>Flexible Querying: SQL allows complex questions to be answered easily</li> <li>ACID Compliance: Transactions are reliable and predictable</li> <li>Scalability: Can handle growing data volumes efficiently</li> </ol>"},{"location":"lectures/Lecture2_Relational_Databases/#12-keys-the-foundation-of-relationships","title":"1.2 Keys: The Foundation of Relationships","text":""},{"location":"lectures/Lecture2_Relational_Databases/#primary-key-pk","title":"Primary Key (PK)","text":"<p>A Primary Key is a column (or combination of columns) that uniquely identifies each row in a table.</p> <p>Rules for Primary Keys: - Must be unique \u2014 no two rows can have the same PK value - Cannot be NULL \u2014 every row must have a value - Should be immutable \u2014 ideally never changes once set - Every table should have exactly one</p> <p>Types of Primary Keys:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     PRIMARY KEY TYPES                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502  1. NATURAL KEY                   2. SURROGATE KEY              \u2502\n\u2502     (Real-world identifier)          (Artificial identifier)    \u2502\n\u2502                                                                 \u2502\n\u2502     Examples:                        Examples:                  \u2502\n\u2502     \u2022 Social Security Number         \u2022 Auto-increment ID        \u2502\n\u2502     \u2022 ISBN for books                 \u2022 UUID/GUID                \u2502\n\u2502     \u2022 Email address                  \u2022 Sequence number          \u2502\n\u2502                                                                 \u2502\n\u2502     Pros: Meaningful                 Pros: Simple, stable       \u2502\n\u2502     Cons: Can change, complex        Cons: No business meaning  \u2502\n\u2502                                                                 \u2502\n\u2502  3. COMPOSITE KEY (Multiple columns together)                   \u2502\n\u2502     Example: (student_id, course_id) for enrollments            \u2502\n\u2502                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>SQL Examples:</p> <pre><code>-- Single column primary key (most common)\nCREATE TABLE customers (\n    customer_id INT PRIMARY KEY,\n    name VARCHAR(100),\n    email VARCHAR(100)\n);\n\n-- Auto-increment primary key\nCREATE TABLE customers (\n    customer_id SERIAL PRIMARY KEY,  -- PostgreSQL\n    -- customer_id INT AUTO_INCREMENT PRIMARY KEY,  -- MySQL\n    name VARCHAR(100),\n    email VARCHAR(100)\n);\n\n-- Composite primary key\nCREATE TABLE order_items (\n    order_id INT,\n    product_id INT,\n    quantity INT,\n    PRIMARY KEY (order_id, product_id)\n);\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#foreign-key-fk","title":"Foreign Key (FK)","text":"<p>A Foreign Key is a column that references a Primary Key in another table, creating a relationship between the two tables.</p> <p>What Foreign Keys Do: - Create relationships between tables - Enforce referential integrity (can't reference non-existent records) - Enable JOIN operations - Prevent orphan records</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      customers      \u2502              \u2502       orders        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524              \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer_id (PK) \u25cf\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u25cb customer_id (FK) \u2502\n\u2502 name                \u2502              \u2502 order_id (PK)       \u2502\n\u2502 email               \u2502              \u2502 order_date          \u2502\n\u2502 city                \u2502              \u2502 total_amount        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u25cf = Primary Key (unique identifier)\n\u25cb = Foreign Key (reference to another table)\n</code></pre> <p>SQL Example:</p> <pre><code>CREATE TABLE orders (\n    order_id INT PRIMARY KEY,\n    customer_id INT,\n    order_date DATE,\n    total_amount DECIMAL(10,2),\n    FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n);\n</code></pre> <p>Referential Integrity Actions:</p> <pre><code>CREATE TABLE orders (\n    order_id INT PRIMARY KEY,\n    customer_id INT,\n    FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n        ON DELETE CASCADE      -- Delete orders when customer deleted\n        ON UPDATE CASCADE      -- Update FK when customer PK changes\n);\n\n-- Other options:\n-- ON DELETE SET NULL     -- Set FK to NULL when parent deleted\n-- ON DELETE RESTRICT     -- Prevent deletion if children exist\n-- ON DELETE NO ACTION    -- Same as RESTRICT (default)\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#13-types-of-relationships","title":"1.3 Types of Relationships","text":""},{"location":"lectures/Lecture2_Relational_Databases/#one-to-many-1n-most-common","title":"One-to-Many (1:N) \u2014 Most Common","text":"<p>One record in Table A can relate to many records in Table B, but each record in Table B relates to only one record in Table A.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      customers      \u2502         \u2502       orders        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524         \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 customer_id (PK)    \u2502\u25c4\u2500\u2500\u2500\u2510    \u2502 order_id (PK)       \u2502\n\u2502 name                \u2502    \u2502    \u2502 customer_id (FK) \u2500\u2500\u2500\u2518\n\u2502 email               \u2502    \u2502    \u2502 order_date          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2502 total_amount        \u2502\n                           \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n    One customer \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Many orders\n</code></pre> <p>Real-world examples: - One customer \u2192 Many orders - One department \u2192 Many employees - One author \u2192 Many blog posts - One category \u2192 Many products</p> <p>Implementation: Place the FK in the \"many\" side table.</p>"},{"location":"lectures/Lecture2_Relational_Databases/#one-to-one-11-rare","title":"One-to-One (1:1) \u2014 Rare","text":"<p>Each record in Table A relates to exactly one record in Table B, and vice versa.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       users         \u2502         \u2502    user_profiles    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524         \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 user_id (PK)        \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 user_id (PK, FK)    \u2502\n\u2502 email               \u2502         \u2502 bio                 \u2502\n\u2502 password_hash       \u2502         \u2502 avatar_url          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502 preferences_json    \u2502\n                                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>When to use: - Optional data that doesn't apply to all records - Security separation (sensitive data in separate table) - Very large columns that are rarely accessed - Exceeding column limits in a table</p> <p>Implementation: FK in either table (usually the optional one), often also the PK.</p>"},{"location":"lectures/Lecture2_Relational_Databases/#many-to-many-mn","title":"Many-to-Many (M:N)","text":"<p>Many records in Table A can relate to many records in Table B.</p> <p>Problem: Cannot be directly represented with just two tables.</p> <p>Solution: Create a junction table (also called bridge/associative table).</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      students       \u2502                           \u2502       courses       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524                           \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 student_id (PK)     \u2502\u25c4\u2500\u2500\u2500\u2510                 \u250c\u2500\u2500\u2500\u25ba\u2502 course_id (PK)      \u2502\n\u2502 name                \u2502    \u2502                 \u2502    \u2502 course_name         \u2502\n\u2502 email               \u2502    \u2502                 \u2502    \u2502 credits             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502                 \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502                 \u2502\n                           \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                           \u2502  \u2502     enrollments       \u2502\n                           \u2502  \u2502   (junction table)    \u2502\n                           \u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                           \u2514\u2500\u2500\u2502 student_id (FK, PK)   \u2502\n                              \u2502 course_id (FK, PK)  \u2500\u2500\u2518\n                              \u2502 enrollment_date       \u2502\n                              \u2502 grade                 \u2502\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>CREATE TABLE enrollments (\n    student_id INT,\n    course_id INT,\n    enrollment_date DATE,\n    grade CHAR(2),\n    PRIMARY KEY (student_id, course_id),  -- Composite PK\n    FOREIGN KEY (student_id) REFERENCES students(student_id),\n    FOREIGN KEY (course_id) REFERENCES courses(course_id)\n);\n</code></pre> <p>Real-world examples: - Students \u2194 Courses (via enrollments) - Products \u2194 Orders (via order_items) - Users \u2194 Roles (via user_roles) - Authors \u2194 Books (via book_authors)</p>"},{"location":"lectures/Lecture2_Relational_Databases/#14-sql-data-types","title":"1.4 SQL Data Types","text":""},{"location":"lectures/Lecture2_Relational_Databases/#numeric-types","title":"Numeric Types","text":"Type Description Range/Precision Use Case <code>TINYINT</code> Very small integer -128 to 127 Status codes, flags <code>SMALLINT</code> Small integer -32,768 to 32,767 Counts, years <code>INT</code>/<code>INTEGER</code> Standard integer ~\u00b12.1 billion IDs, counts <code>BIGINT</code> Large integer ~\u00b19.2 quintillion Large IDs, timestamps <code>DECIMAL(p,s)</code> Fixed precision p digits, s after decimal Money, exact values <code>NUMERIC(p,s)</code> Same as DECIMAL p digits, s after decimal Money, exact values <code>FLOAT</code> Single precision ~7 significant digits Scientific data <code>DOUBLE</code>/<code>REAL</code> Double precision ~15 significant digits Scientific data <pre><code>-- DECIMAL is crucial for money (no floating point errors)\nCREATE TABLE products (\n    price DECIMAL(10, 2),     -- 10 digits total, 2 after decimal\n    tax_rate DECIMAL(5, 4)    -- e.g., 0.0825 for 8.25%\n);\n\n-- NEVER use FLOAT for money!\n-- 0.1 + 0.2 = 0.30000000000000004 in floating point\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#string-types","title":"String Types","text":"Type Description Max Length Use Case <code>CHAR(n)</code> Fixed-length string n characters (padded) Country codes, status <code>VARCHAR(n)</code> Variable-length string Up to n characters Names, emails <code>TEXT</code> Long text ~65KB to unlimited Descriptions, articles <code>MEDIUMTEXT</code> Medium long text ~16MB Blog posts <code>LONGTEXT</code> Very long text ~4GB Documents <pre><code>-- CHAR vs VARCHAR\nCREATE TABLE countries (\n    country_code CHAR(2),       -- Always 2 chars: 'US', 'CA'\n    country_name VARCHAR(100)   -- Variable: 'USA', 'United Kingdom'\n);\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#date-and-time-types","title":"Date and Time Types","text":"Type Format Example Use Case <code>DATE</code> YYYY-MM-DD 2025-11-29 Birthdates, due dates <code>TIME</code> HH:MM:SS 14:30:00 Schedules, durations <code>DATETIME</code> YYYY-MM-DD HH:MM:SS 2025-11-29 14:30:00 Events, logs <code>TIMESTAMP</code> Unix timestamp or datetime 2025-11-29 14:30:00 UTC Auto-tracking, sync <code>YEAR</code> YYYY 2025 Years only <pre><code>CREATE TABLE events (\n    event_date DATE,\n    start_time TIME,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP\n);\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#other-types","title":"Other Types","text":"Type Description Use Case <code>BOOLEAN</code> TRUE/FALSE Flags, toggles <code>ENUM</code> Predefined values Status, categories <code>JSON</code> JSON data Flexible schemas <code>BLOB</code> Binary data Images, files <code>UUID</code> Universally unique ID Distributed systems <pre><code>CREATE TABLE users (\n    is_active BOOLEAN DEFAULT TRUE,\n    status ENUM('pending', 'active', 'suspended'),\n    preferences JSON,\n    avatar BLOB\n);\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#15-acid-properties","title":"1.5 ACID Properties","text":"<p>ACID properties ensure database transactions are processed reliably.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            ACID PROPERTIES                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557    A transaction is an \"all or nothing\" operation.       \u2502\n\u2502  \u2551  ATOMICITY    \u2551    Either ALL operations succeed, or NONE do.            \u2502\n\u2502  \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d    Example: Bank transfer - debit AND credit both        \u2502\n\u2502                       happen, or neither happens.                           \u2502\n\u2502                                                                             \u2502\n\u2502  \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557    Database moves from one valid state to another.       \u2502\n\u2502  \u2551  CONSISTENCY  \u2551    All rules, constraints, and triggers are enforced.    \u2502\n\u2502  \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d    Example: Account balance can never go negative        \u2502\n\u2502                       if that's a defined constraint.                       \u2502\n\u2502                                                                             \u2502\n\u2502  \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557    Concurrent transactions don't interfere.              \u2502\n\u2502  \u2551  ISOLATION    \u2551    Each transaction sees a consistent snapshot.          \u2502\n\u2502  \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d    Example: Two people buying last item - only one       \u2502\n\u2502                       succeeds, the other sees \"out of stock.\"              \u2502\n\u2502                                                                             \u2502\n\u2502  \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557    Committed transactions are permanent.                 \u2502\n\u2502  \u2551  DURABILITY   \u2551    Data survives system crashes, power failures.         \u2502\n\u2502  \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d    Example: Confirmed order stays confirmed even         \u2502\n\u2502                       if server crashes immediately after.                  \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Transaction Example:</p> <pre><code>-- Bank transfer: Move $100 from Account A to Account B\nBEGIN TRANSACTION;\n\nUPDATE accounts SET balance = balance - 100 WHERE account_id = 'A';\nUPDATE accounts SET balance = balance + 100 WHERE account_id = 'B';\n\n-- If both succeed:\nCOMMIT;\n\n-- If anything fails:\nROLLBACK;  -- Undoes everything, account balances unchanged\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#part-2-database-normalization","title":"Part 2: Database Normalization","text":""},{"location":"lectures/Lecture2_Relational_Databases/#21-why-normalize","title":"2.1 Why Normalize?","text":""},{"location":"lectures/Lecture2_Relational_Databases/#the-problem-non-normalized-data","title":"The Problem: Non-Normalized Data","text":"<p>Consider storing all order information in a single table:</p> <p>orders_denormalized | order_id | customer_name | customer_email | city | product | price | qty | |----------|---------------|----------------|------|---------|-------|-----| | 101 | Alice | alice@email.com | NYC | Laptop | 999.00 | 1 | | 102 | Alice | alice@email.com | NYC | Mouse | 29.00 | 2 | | 103 | Alice | alice@email.com | NYC | Keyboard | 79.00 | 1 | | 104 | Bob | bob@email.com | LA | Laptop | 999.00 | 1 |</p>"},{"location":"lectures/Lecture2_Relational_Databases/#problems-identified","title":"Problems Identified","text":"<p>1. Data Redundancy - Alice's name, email, and city are stored 3 times - \"Laptop\" price is stored twice - Wastes storage space - More data to maintain</p> <p>2. Update Anomaly If Alice changes her email, you must update EVERY row:</p> <pre><code>-- Must update 3 rows!\nUPDATE orders_denormalized\nSET customer_email = 'alice.new@email.com'\nWHERE customer_name = 'Alice';\n\n-- RISK: If you miss one row, data becomes inconsistent\n</code></pre> <p>3. Insert Anomaly Can't add a new customer until they place an order:</p> <pre><code>-- FAILS! What values for order_id, product, price, qty?\nINSERT INTO orders_denormalized (customer_name, customer_email, city)\nVALUES ('Charlie', 'charlie@email.com', 'Chicago');\n</code></pre> <p>4. Delete Anomaly Deleting Bob's only order loses Bob's information entirely:</p> <pre><code>-- Bob is gone from the database!\nDELETE FROM orders_denormalized WHERE customer_name = 'Bob';\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#the-solution-normalization","title":"The Solution: Normalization","text":"<p>Normalization is the process of organizing data into multiple related tables, each storing one type of entity, to eliminate redundancy and prevent anomalies.</p> <pre><code>                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502    customers    \u2502\n                    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                    \u2502 customer_id (PK)\u2502\n                    \u2502 name            \u2502\n                    \u2502 email           \u2502\n                    \u2502 city            \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n                             \u2502 1:N\n                             \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502     orders      \u2502\n                    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                    \u2502 order_id (PK)   \u2502\n                    \u2502 customer_id (FK)\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502 order_date      \u2502          \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n                             \u2502                   \u2502\n                             \u2502 1:N               \u2502\n                             \u2502                   \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n                    \u2502   order_items   \u2502          \u2502\n                    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524          \u2502\n                    \u2502 order_id (FK,PK)\u2502          \u2502\n                    \u2502 product_id(FK,PK)\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2510\n                    \u2502 quantity        \u2502          \u2502   \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502   \u2502\n                                                 \u2502   \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502   \u2502\n                    \u2502    products     \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n                    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524              \u2502\n                    \u2502 product_id (PK) \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502 name            \u2502\n                    \u2502 price           \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#22-normal-forms","title":"2.2 Normal Forms","text":""},{"location":"lectures/Lecture2_Relational_Databases/#first-normal-form-1nf","title":"First Normal Form (1NF)","text":"<p>Requirements: 1. Each column contains only atomic (indivisible) values 2. No repeating groups or arrays within a cell 3. Each row is unique (has a primary key) 4. Each column has a unique name</p> <p>Violation Example:</p> order_id customer products 101 Alice Laptop, Mouse, Keyboard <p>Problem: Multiple values in the \"products\" cell. Cannot easily query individual products.</p> <p>1NF Solution:</p> order_id customer product 101 Alice Laptop 101 Alice Mouse 101 Alice Keyboard <pre><code>-- Non-1NF (bad - array in column)\nCREATE TABLE orders_bad (\n    order_id INT,\n    customer VARCHAR(100),\n    products TEXT  -- \"Laptop, Mouse, Keyboard\"\n);\n\n-- 1NF compliant\nCREATE TABLE order_items (\n    order_id INT,\n    customer VARCHAR(100),\n    product VARCHAR(100),\n    PRIMARY KEY (order_id, product)\n);\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#second-normal-form-2nf","title":"Second Normal Form (2NF)","text":"<p>Requirements: 1. Must be in 1NF 2. No partial dependencies \u2014 every non-key column depends on the ENTIRE primary key, not just part of it</p> <p>Only applies to tables with composite primary keys.</p> <p>Violation Example:</p> <p>Composite PK: (order_id, product_id)</p> order_id product_id customer_name product_name quantity 101 1 Alice Laptop 1 <p>Problems: - <code>customer_name</code> depends only on <code>order_id</code> (partial dependency) - <code>product_name</code> depends only on <code>product_id</code> (partial dependency)</p> <p>2NF Solution: Split into separate tables:</p> <pre><code>-- orders table (customer depends on full order)\nCREATE TABLE orders (\n    order_id INT PRIMARY KEY,\n    customer_id INT\n);\n\n-- products table (product_name depends on full product)\nCREATE TABLE products (\n    product_id INT PRIMARY KEY,\n    product_name VARCHAR(100)\n);\n\n-- order_items (quantity depends on both order AND product)\nCREATE TABLE order_items (\n    order_id INT,\n    product_id INT,\n    quantity INT,\n    PRIMARY KEY (order_id, product_id)\n);\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#third-normal-form-3nf","title":"Third Normal Form (3NF)","text":"<p>Requirements: 1. Must be in 2NF 2. No transitive dependencies \u2014 non-key columns cannot depend on other non-key columns</p> <p>Violation Example:</p> customer_id name city city_zip 1 Alice NYC 10001 2 Bob NYC 10001 <p>Problem: <code>city_zip</code> depends on <code>city</code>, not directly on <code>customer_id</code>. This is a transitive dependency: <pre><code>customer_id \u2192 city \u2192 city_zip\n</code></pre></p> <p>3NF Solution:</p> <pre><code>-- customers table\nCREATE TABLE customers (\n    customer_id INT PRIMARY KEY,\n    name VARCHAR(100),\n    city_id INT\n);\n\n-- cities table\nCREATE TABLE cities (\n    city_id INT PRIMARY KEY,\n    city_name VARCHAR(100),\n    zip_code VARCHAR(10)\n);\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#summary-of-normal-forms","title":"Summary of Normal Forms","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         NORMAL FORMS PROGRESSION                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                            \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502   \u2502   1NF   \u2502  \u25ba Atomic values only                                        \u2502\n\u2502   \u2502         \u2502  \u25ba No repeating groups                                       \u2502\n\u2502   \u2502         \u2502  \u25ba Has primary key                                           \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502        \u2502                                                                   \u2502\n\u2502        \u25bc                                                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502   \u2502   2NF   \u2502  \u25ba Must be in 1NF                                            \u2502\n\u2502   \u2502         \u2502  \u25ba No partial dependencies                                   \u2502\n\u2502   \u2502         \u2502  \u25ba (All columns depend on ENTIRE PK)                         \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502        \u2502                                                                   \u2502\n\u2502        \u25bc                                                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502   \u2502   3NF   \u2502  \u25ba Must be in 2NF                                            \u2502\n\u2502   \u2502         \u2502  \u25ba No transitive dependencies                                \u2502\n\u2502   \u2502         \u2502  \u25ba (Non-key columns don't depend on each other)              \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502        \u2502                                                                   \u2502\n\u2502        \u25bc                                                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                              \u2502\n\u2502   \u2502  BCNF   \u2502  \u25ba Must be in 3NF                                            \u2502\n\u2502   \u2502         \u2502  \u25ba Every determinant is a candidate key                      \u2502\n\u2502   \u2502         \u2502  \u25ba (Stricter version of 3NF)                                 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                              \u2502\n\u2502                                                                            \u2502\n\u2502   Most production databases aim for 3NF \u2014 good balance of                  \u2502\n\u2502   data integrity and query performance.                                    \u2502\n\u2502                                                                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#higher-normal-forms-brief-overview","title":"Higher Normal Forms (Brief Overview)","text":"<p>Boyce-Codd Normal Form (BCNF): - Stricter than 3NF - Every determinant must be a candidate key - Handles rare edge cases in 3NF</p> <p>Fourth Normal Form (4NF): - No multi-valued dependencies - Example: Employee skills and languages stored separately</p> <p>Fifth Normal Form (5NF): - No join dependencies - Extremely rare in practice</p>"},{"location":"lectures/Lecture2_Relational_Databases/#23-when-to-denormalize","title":"2.3 When to Denormalize","text":"<p>While normalization is generally good, denormalization (intentionally violating normal forms) is sometimes used for performance.</p> <p>Scenarios for Denormalization:</p> Scenario Why Denormalize? Read-heavy workloads JOINs are expensive; pre-joined data speeds up reads Data warehouses Analytics queries benefit from star/snowflake schemas Reporting tables Pre-aggregate data for dashboards Caching layers Store computed values for performance High-traffic applications Reduce query complexity at read time <p>Example: Storing order total instead of calculating</p> <pre><code>-- Normalized (calculate total each time)\nSELECT SUM(oi.quantity * p.price) as total\nFROM order_items oi\nJOIN products p ON oi.product_id = p.product_id\nWHERE oi.order_id = 101;\n\n-- Denormalized (stored total)\nSELECT total_amount FROM orders WHERE order_id = 101;\n</code></pre> <p>Trade-off: Faster reads, but must update <code>total_amount</code> whenever items change.</p>"},{"location":"lectures/Lecture2_Relational_Databases/#part-3-sql-queries-from-basic-to-advanced","title":"Part 3: SQL Queries - From Basic to Advanced","text":""},{"location":"lectures/Lecture2_Relational_Databases/#31-select-reading-data","title":"3.1 SELECT - Reading Data","text":""},{"location":"lectures/Lecture2_Relational_Databases/#basic-select","title":"Basic SELECT","text":"<pre><code>-- Select all columns from a table\nSELECT * FROM customers;\n\n-- Select specific columns\nSELECT customer_id, name, email FROM customers;\n\n-- Select with column aliases\nSELECT \n    customer_id AS id,\n    name AS customer_name,\n    email AS contact_email\nFROM customers;\n\n-- Select with expressions\nSELECT \n    product_name,\n    price,\n    price * 0.9 AS discounted_price,\n    price * 1.08 AS price_with_tax\nFROM products;\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#distinct-removing-duplicates","title":"DISTINCT - Removing Duplicates","text":"<pre><code>-- Get unique cities\nSELECT DISTINCT city FROM customers;\n\n-- Get unique combinations\nSELECT DISTINCT city, state FROM customers;\n\n-- Count unique values\nSELECT COUNT(DISTINCT city) AS unique_cities FROM customers;\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#32-where-filtering-data","title":"3.2 WHERE - Filtering Data","text":""},{"location":"lectures/Lecture2_Relational_Databases/#comparison-operators","title":"Comparison Operators","text":"<pre><code>-- Equals\nSELECT * FROM products WHERE price = 99.99;\n\n-- Not equals\nSELECT * FROM products WHERE category &lt;&gt; 'Electronics';\nSELECT * FROM products WHERE category != 'Electronics';\n\n-- Greater than / Less than\nSELECT * FROM orders WHERE total_amount &gt; 100;\nSELECT * FROM orders WHERE total_amount &gt;= 100;\nSELECT * FROM orders WHERE order_date &lt; '2025-01-01';\nSELECT * FROM orders WHERE order_date &lt;= '2025-01-01';\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#logical-operators","title":"Logical Operators","text":"<pre><code>-- AND (all conditions must be true)\nSELECT * FROM orders \nWHERE total_amount &gt; 100 \n  AND order_date &gt;= '2025-01-01';\n\n-- OR (at least one condition must be true)\nSELECT * FROM customers \nWHERE city = 'NYC' \n   OR city = 'LA';\n\n-- NOT (negates condition)\nSELECT * FROM products \nWHERE NOT category = 'Electronics';\n\n-- Combined with parentheses\nSELECT * FROM orders \nWHERE (status = 'pending' OR status = 'processing')\n  AND total_amount &gt; 50;\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#special-operators","title":"Special Operators","text":"<pre><code>-- IN (match any value in list)\nSELECT * FROM customers \nWHERE city IN ('NYC', 'LA', 'Chicago', 'Miami');\n\n-- NOT IN\nSELECT * FROM customers \nWHERE city NOT IN ('NYC', 'LA');\n\n-- BETWEEN (inclusive range)\nSELECT * FROM orders \nWHERE order_date BETWEEN '2025-01-01' AND '2025-12-31';\n\nSELECT * FROM products \nWHERE price BETWEEN 10 AND 100;\n\n-- LIKE (pattern matching)\nSELECT * FROM customers WHERE email LIKE '%@gmail.com';   -- Ends with\nSELECT * FROM customers WHERE name LIKE 'John%';          -- Starts with\nSELECT * FROM customers WHERE name LIKE '%son%';          -- Contains\nSELECT * FROM products WHERE sku LIKE 'PRD-___';          -- Exactly 3 chars after PRD-\n\n-- IS NULL / IS NOT NULL\nSELECT * FROM customers WHERE phone IS NULL;\nSELECT * FROM orders WHERE shipped_date IS NOT NULL;\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#33-order-by-limit","title":"3.3 ORDER BY &amp; LIMIT","text":""},{"location":"lectures/Lecture2_Relational_Databases/#order-by-sorting-results","title":"ORDER BY - Sorting Results","text":"<pre><code>-- Sort ascending (default)\nSELECT * FROM products ORDER BY price;\nSELECT * FROM products ORDER BY price ASC;\n\n-- Sort descending\nSELECT * FROM products ORDER BY price DESC;\n\n-- Multiple columns (sort by first, then by second for ties)\nSELECT * FROM orders \nORDER BY customer_id ASC, order_date DESC;\n\n-- Sort by expression\nSELECT product_name, price, price * quantity AS total\nFROM order_items\nORDER BY price * quantity DESC;\n\n-- Sort by column position (not recommended for readability)\nSELECT customer_id, name, city FROM customers\nORDER BY 3;  -- Sorts by city\n\n-- Sort with NULLs first/last\nSELECT * FROM employees ORDER BY manager_id NULLS FIRST;\nSELECT * FROM employees ORDER BY manager_id NULLS LAST;\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#limit-restricting-results","title":"LIMIT - Restricting Results","text":"<pre><code>-- Get first 10 rows\nSELECT * FROM customers LIMIT 10;\n\n-- Top 5 highest spending customers\nSELECT customer_id, SUM(total_amount) AS total_spent\nFROM orders\nGROUP BY customer_id\nORDER BY total_spent DESC\nLIMIT 5;\n\n-- Pagination (OFFSET)\n-- Page 1: rows 1-10\nSELECT * FROM products ORDER BY product_id LIMIT 10 OFFSET 0;\n\n-- Page 2: rows 11-20\nSELECT * FROM products ORDER BY product_id LIMIT 10 OFFSET 10;\n\n-- Page 3: rows 21-30\nSELECT * FROM products ORDER BY product_id LIMIT 10 OFFSET 20;\n\n-- Alternative syntax (MySQL)\nSELECT * FROM products ORDER BY product_id LIMIT 10, 10;  -- LIMIT offset, count\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#34-aggregate-functions","title":"3.4 Aggregate Functions","text":""},{"location":"lectures/Lecture2_Relational_Databases/#basic-aggregates","title":"Basic Aggregates","text":"<pre><code>-- COUNT - number of rows\nSELECT COUNT(*) AS total_rows FROM orders;\nSELECT COUNT(phone) AS customers_with_phone FROM customers;  -- Excludes NULLs\nSELECT COUNT(DISTINCT customer_id) AS unique_customers FROM orders;\n\n-- SUM - total of numeric values\nSELECT SUM(total_amount) AS total_revenue FROM orders;\n\n-- AVG - average value\nSELECT AVG(total_amount) AS avg_order_value FROM orders;\n\n-- MIN / MAX\nSELECT MIN(price) AS cheapest, MAX(price) AS most_expensive FROM products;\nSELECT MIN(order_date) AS first_order, MAX(order_date) AS last_order FROM orders;\n\n-- Multiple aggregates together\nSELECT \n    COUNT(*) AS num_orders,\n    SUM(total_amount) AS total_revenue,\n    AVG(total_amount) AS avg_order,\n    MIN(total_amount) AS smallest_order,\n    MAX(total_amount) AS largest_order\nFROM orders;\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#statistical-aggregates","title":"Statistical Aggregates","text":"<pre><code>-- Standard deviation\nSELECT STDDEV(price) AS price_stddev FROM products;\nSELECT STDDEV_POP(price) AS population_stddev FROM products;\nSELECT STDDEV_SAMP(price) AS sample_stddev FROM products;\n\n-- Variance\nSELECT VARIANCE(price) AS price_variance FROM products;\nSELECT VAR_POP(price) AS population_variance FROM products;\nSELECT VAR_SAMP(price) AS sample_variance FROM products;\n\n-- Percentile (PostgreSQL)\nSELECT \n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) AS median_price,\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY price) AS q1,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY price) AS q3\nFROM products;\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#35-group-by-grouping-data","title":"3.5 GROUP BY - Grouping Data","text":""},{"location":"lectures/Lecture2_Relational_Databases/#basic-grouping","title":"Basic Grouping","text":"<pre><code>-- Orders per customer\nSELECT \n    customer_id,\n    COUNT(*) AS num_orders,\n    SUM(total_amount) AS total_spent,\n    AVG(total_amount) AS avg_order_value\nFROM orders\nGROUP BY customer_id;\n\n-- Products per category\nSELECT \n    category,\n    COUNT(*) AS product_count,\n    AVG(price) AS avg_price,\n    MIN(price) AS min_price,\n    MAX(price) AS max_price\nFROM products\nGROUP BY category;\n\n-- Multiple grouping columns\nSELECT \n    EXTRACT(YEAR FROM order_date) AS year,\n    EXTRACT(MONTH FROM order_date) AS month,\n    COUNT(*) AS num_orders,\n    SUM(total_amount) AS monthly_revenue\nFROM orders\nGROUP BY EXTRACT(YEAR FROM order_date), EXTRACT(MONTH FROM order_date)\nORDER BY year, month;\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#date-grouping","title":"Date Grouping","text":"<pre><code>-- Group by date (daily)\nSELECT \n    DATE(order_date) AS order_day,\n    COUNT(*) AS num_orders,\n    SUM(total_amount) AS daily_revenue\nFROM orders\nGROUP BY DATE(order_date)\nORDER BY order_day;\n\n-- Group by week\nSELECT \n    DATE_TRUNC('week', order_date) AS week_start,\n    COUNT(*) AS num_orders\nFROM orders\nGROUP BY DATE_TRUNC('week', order_date);\n\n-- Group by month\nSELECT \n    DATE_TRUNC('month', order_date) AS month,\n    SUM(total_amount) AS monthly_revenue\nFROM orders\nGROUP BY DATE_TRUNC('month', order_date)\nORDER BY month;\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#36-having-filtering-groups","title":"3.6 HAVING - Filtering Groups","text":"<p>WHERE filters rows BEFORE grouping. HAVING filters groups AFTER aggregation.</p> <pre><code>-- Customers with more than 5 orders\nSELECT \n    customer_id,\n    COUNT(*) AS num_orders\nFROM orders\nGROUP BY customer_id\nHAVING COUNT(*) &gt; 5;\n\n-- Categories with average price over $50\nSELECT \n    category,\n    AVG(price) AS avg_price\nFROM products\nGROUP BY category\nHAVING AVG(price) &gt; 50;\n\n-- Combined WHERE and HAVING\nSELECT \n    customer_id,\n    COUNT(*) AS num_orders,\n    SUM(total_amount) AS total_spent\nFROM orders\nWHERE order_date &gt;= '2025-01-01'    -- Filter rows first\nGROUP BY customer_id\nHAVING SUM(total_amount) &gt; 1000;    -- Then filter groups\n</code></pre>"},{"location":"lectures/Lecture2_Relational_Databases/#where-vs-having-comparison","title":"WHERE vs HAVING Comparison","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      WHERE vs HAVING                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                     \u2502\n\u2502   WHERE                          HAVING                             \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500      \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500          \u2502\n\u2502   \u2022 Filters individual ROWS      \u2022 Filters GROUPS                   \u2502\n\u2502   \u2022 Applied BEFORE grouping      \u2022 Applied AFTER grouping           \u2502\n\u2502   \u2022 Cannot use aggregates        \u2022 Can use aggregate functions      \u2502\n\u2502   \u2022 Faster (reduces data early)  \u2022 Works on aggregated results      \u2502\n\u2502                                                                     \u2502\n\u2502   Example:                       Example:                           \u2502\n\u2502   WHERE order_date &gt; '2025'      HAVING COUNT(*) &gt; 5                \u2502\n\u2502   WHERE price &lt; 100              HAVING SUM(amount) &gt; 1000          \u2502\n\u2502                                                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"lectures/course_outline/","title":"Data Science Applications Course","text":"<p>Duration: 4 months</p>"},{"location":"lectures/course_outline/#module-1-data-science-fundamentals-and-exploratory-data-analysis-eda","title":"Module 1: Data Science Fundamentals and Exploratory Data Analysis (EDA)","text":""},{"location":"lectures/course_outline/#11-introduction-to-data-science-tools-and-environments","title":"1.1 Introduction to Data Science Tools and Environments","text":"<p>Key Topics: - Overview of Data Science Roles and Tools</p>"},{"location":"lectures/course_outline/#12-big-data-technologies-and-data-engineering","title":"1.2 Big Data Technologies and Data Engineering","text":"<p>Key Topics: - Introduction to Big Data Ecosystem (Hadoop, Spark) - Intro to Databases - Introduction to SQL for Data Retrieval and Manipulation - Introduction to NoSQL Databases (MongoDB) - Data Processing with Apache Spark (PySpark) - Building ETL Pipelines for Big Data - Practical Sessions: Working with Big Data Tools and Techniques</p>"},{"location":"lectures/course_outline/#13-full-etl-and-eda-on-real-world-datasets","title":"1.3 Full ETL and EDA on Real-World Datasets","text":""},{"location":"lectures/course_outline/#module-2-advanced-statistical-methods-and-machine-learning-for-data-science","title":"Module 2: Advanced Statistical Methods and Machine Learning for Data Science","text":""},{"location":"lectures/course_outline/#21-advanced-statistical-methods","title":"2.1 Advanced Statistical Methods","text":"<p>Key Topics: - Hypothesis Testing (T-tests, Chi-Square Tests) - Analysis of Variance (ANOVA) - Regression Analysis (Linear, Logistic, and Polynomial Regression) - Time Series Analysis and Forecasting - Practice: Applying Advanced Statistical Methods</p>"},{"location":"lectures/course_outline/#22-machine-learning-algorithms-for-data-science","title":"2.2 Machine Learning Algorithms for Data Science","text":"<p>Key Topics: - Supervised Learning Algorithms (Decision Trees, Random Forests, Gradient Boosting Machines) - Unsupervised Learning Algorithms (K-Means, Hierarchical Clustering, DBSCAN) - Introduction to Ensemble Methods - Model Evaluation and Validation Techniques (Cross-Validation, ROC-AUC, Precision-Recall) - Practice: Implementing ML Algorithms on Real Datasets</p>"},{"location":"lectures/course_outline/#module-3-deep-learning-for-data-science","title":"Module 3: Deep Learning for Data Science","text":""},{"location":"lectures/course_outline/#31-introduction-to-deep-learning-and-specialized-applications","title":"3.1 Introduction to Deep Learning and Specialized Applications","text":"<p>Key Topics: - Fundamentals of Neural Networks and Deep Learning - Building and Training Deep Learning Models (Using TensorFlow/Keras, PyTorch) - Convolutional Neural Networks (CNNs) for Image Data - Recurrent Neural Networks (RNNs) for Time-Series Data - Natural Language Processing (NLP) for Text Data - Advanced Time Series Analysis and Forecasting Techniques - Practical Sessions: Developing and Tuning Deep Learning Models</p>"},{"location":"lectures/course_outline/#module-4-capstone-project","title":"Module 4: Capstone Project","text":""},{"location":"lectures/course_outline/#41-capstone-project-preparation-execution-and-implementation","title":"4.1 Capstone Project Preparation, Execution, and Implementation","text":"<p>Key Topics: 1. Project Planning and Design 2. Data Collection and Preprocessing Strategies 3. Model Selection and Evaluation Plan 4. Proposal Presentation and Feedback 5. Building and Refining the Data Science Solution 6. Model Training, Tuning, and Evaluation 7. Deployment of the Model (on Cloud or On-Premise) 8. Preparing Final Presentation and Documentation</p>"},{"location":"lectures/course_outline/#42-capstone-project-completion-presentation-and-review","title":"4.2 Capstone Project Completion, Presentation, and Review","text":"<p>Key Topics: 1. Project Presentation to Peers and Instructors 2. Feedback and Q&amp;A Sessions 3. Final Grading and Evaluation 4. Course Wrap-Up and Future Directions in Data Science</p>"},{"location":"lectures/course_outline/#course-overview-summary","title":"Course Overview Summary","text":"Module Focus Area Duration Module 1 Data Science Fundamentals &amp; EDA ~4-6 weeks Module 2 Advanced Statistics &amp; Machine Learning ~6-8 weeks Module 3 Deep Learning ~4-6 weeks Module 4 Capstone Project 4 weeks Total Complete Course 4 months"},{"location":"lectures/course_outline/#learning-outcomes","title":"Learning Outcomes","text":"<p>By the end of this course, students will be able to:</p> <p>\u2705 Work with big data technologies (Hadoop, Spark, PySpark) \u2705 Design and implement ETL pipelines \u2705 Perform comprehensive exploratory data analysis \u2705 Apply advanced statistical methods and hypothesis testing \u2705 Build and evaluate machine learning models \u2705 Develop deep learning solutions for various data types \u2705 Deploy data science solutions to production \u2705 Complete an end-to-end data science project from conception to deployment</p>"},{"location":"lectures/course_outline/#prerequisites","title":"Prerequisites","text":"<ul> <li>Basic Python programming knowledge</li> <li>Fundamental statistics and mathematics</li> <li>Understanding of basic data structures and algorithms</li> <li>Familiarity with Jupyter notebooks (recommended)</li> </ul>"},{"location":"lectures/course_outline/#tools-and-technologies-covered","title":"Tools and Technologies Covered","text":""},{"location":"lectures/course_outline/#programming-languages","title":"Programming Languages","text":"<ul> <li>Python (primary)</li> <li>SQL</li> </ul>"},{"location":"lectures/course_outline/#big-data-technologies","title":"Big Data Technologies","text":"<ul> <li>Apache Hadoop</li> <li>Apache Spark</li> <li>PySpark</li> </ul>"},{"location":"lectures/course_outline/#databases","title":"Databases","text":"<ul> <li>SQL databases</li> <li>MongoDB (NoSQL)</li> </ul>"},{"location":"lectures/course_outline/#machine-learning-frameworks","title":"Machine Learning Frameworks","text":"<ul> <li>Scikit-learn</li> <li>TensorFlow</li> <li>Keras</li> <li>PyTorch</li> </ul>"},{"location":"lectures/course_outline/#development-tools","title":"Development Tools","text":"<ul> <li>Jupyter Notebooks</li> <li>Git/GitHub</li> <li>Cloud platforms (AWS/Azure/GCP)</li> </ul>"},{"location":"lectures/course_outline/#assessment-methods","title":"Assessment Methods","text":"<ol> <li>Hands-on Assignments - Practical exercises throughout each module</li> <li>Project Work - Real-world dataset analysis and model building</li> <li>Capstone Project - Comprehensive end-to-end data science project</li> <li>Presentations - Project proposals and final presentations</li> <li>Peer Review - Collaborative learning and feedback sessions</li> </ol>"}]}